{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3010,"status":"ok","timestamp":1718875224981,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"HaVZ9PiiyiKu","outputId":"fde75d10-6f6c-46f5-97de-2b8435caf781"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718875224982,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"h-tVjAsGyiKx"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"u_GGEhMZzI1R"},"source":["# Part 1. Install necessary independences"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150840,"status":"ok","timestamp":1718875375817,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"vny0X0nHzIa1","outputId":"67751e6c-1bfc-4ba1-c0dd-f671f65dcb9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wrds in /usr/local/lib/python3.10/site-packages (3.2.0)\n","Requirement already satisfied: numpy<1.27,>=1.26 in /usr/local/lib/python3.10/site-packages (from wrds) (1.26.4)\n","Requirement already satisfied: packaging<23.3 in /usr/local/lib/python3.10/site-packages (from wrds) (23.2)\n","Requirement already satisfied: pandas<2.3,>=2.2 in /usr/local/lib/python3.10/site-packages (from wrds) (2.2.2)\n","Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.10/site-packages (from wrds) (2.9.9)\n","Collecting scipy<1.13,>=1.12 (from wrds)\n","  Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Requirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.10/site-packages (from wrds) (2.0.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas<2.3,>=2.2->wrds) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/site-packages (from sqlalchemy<2.1,>=2->wrds) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from sqlalchemy<2.1,>=2->wrds) (3.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.16.0)\n","Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","osqp 0.6.7 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed scipy-1.12.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: swig in /usr/local/lib/python3.10/site-packages (4.2.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: PyPortfolioOpt in /usr/local/lib/python3.10/site-packages (1.5.5)\n","Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/site-packages (from PyPortfolioOpt) (1.5.2)\n","Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.10/site-packages (from PyPortfolioOpt) (1.26.4)\n","Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/site-packages (from PyPortfolioOpt) (2.2.2)\n","Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.10/site-packages (from PyPortfolioOpt) (1.12.0)\n","Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (0.6.7)\n","Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (2.0.14)\n","Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (0.9.0)\n","Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (3.2.4.post3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=0.19->PyPortfolioOpt) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=0.19->PyPortfolioOpt) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=0.19->PyPortfolioOpt) (2024.1)\n","Collecting scipy<2.0,>=1.3 (from PyPortfolioOpt)\n","  Using cached scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Requirement already satisfied: qdldl in /usr/local/lib/python3.10/site-packages (from osqp>=0.6.2->cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (0.1.7.post3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.19->PyPortfolioOpt) (1.16.0)\n","Using cached scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.12.0\n","    Uninstalling scipy-1.12.0:\n","      Successfully uninstalled scipy-1.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","wrds 3.2.0 requires scipy<1.13,>=1.12, but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed scipy-1.13.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: pyfolio-reloaded in /usr/local/lib/python3.10/site-packages (0.9.7)\n","Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (8.25.0)\n","Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (3.9.0)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (1.26.4)\n","Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (2.2.2)\n","Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (2024.1)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (1.5.0)\n","Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (0.13.2)\n","Requirement already satisfied: empyrical-reloaded>=0.5.9 in /usr/local/lib/python3.10/site-packages (from pyfolio-reloaded) (0.5.10)\n","Requirement already satisfied: bottleneck>=1.3.0 in /usr/local/lib/python3.10/site-packages (from empyrical-reloaded>=0.5.9->pyfolio-reloaded) (1.4.0)\n","Requirement already satisfied: peewee<3.17.4 in /usr/local/lib/python3.10/site-packages (from empyrical-reloaded>=0.5.9->pyfolio-reloaded) (3.17.3)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (0.1.7)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (3.0.47)\n","Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (2.18.0)\n","Requirement already satisfied: stack-data in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (0.6.3)\n","Requirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (5.14.3)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (1.2.1)\n","Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (4.12.2)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (4.9.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (23.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (2.9.0.post0)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.3->pyfolio-reloaded) (2024.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=0.16.1->pyfolio-reloaded) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=0.16.1->pyfolio-reloaded) (3.5.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio-reloaded) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio-reloaded) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio-reloaded) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->pyfolio-reloaded) (1.16.0)\n","Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded) (2.4.1)\n","Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded) (0.2.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: stockstats in /usr/local/lib/python3.10/site-packages (0.6.2)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/site-packages (from stockstats) (1.26.4)\n","Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/site-packages (from stockstats) (2.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24.2->stockstats) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24.2->stockstats) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24.2->stockstats) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->stockstats) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: gym in /usr/local/lib/python3.10/site-packages (0.26.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/site-packages (from gym) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/site-packages (from gym) (3.0.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/site-packages (from gym) (0.0.8)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: gymnasium in /usr/local/lib/python3.10/site-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/site-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/site-packages (from gymnasium) (3.0.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/site-packages (from gymnasium) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting stable_baselines3\n","  Using cached stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/site-packages (from stable_baselines3) (0.29.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/site-packages (from stable_baselines3) (1.26.4)\n","Collecting torch>=1.13 (from stable_baselines3)\n","  Using cached torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/site-packages (from stable_baselines3) (3.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from stable_baselines3) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (from stable_baselines3) (3.9.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n","Collecting filelock (from torch>=1.13->stable_baselines3)\n","  Using cached filelock-3.15.3-py3-none-any.whl.metadata (2.9 kB)\n","Collecting sympy (from torch>=1.13->stable_baselines3)\n","  Using cached sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch>=1.13->stable_baselines3)\n","  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n","Collecting jinja2 (from torch>=1.13->stable_baselines3)\n","  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n","Collecting fsspec (from torch>=1.13->stable_baselines3)\n","  Using cached fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable_baselines3)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.3.1 (from torch>=1.13->stable_baselines3)\n","  Using cached triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable_baselines3)\n","  Using cached nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (23.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->stable_baselines3) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->stable_baselines3) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n","Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.13->stable_baselines3)\n","  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch>=1.13->stable_baselines3)\n","  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n","Using cached stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n","Using cached torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Using cached triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","Using cached filelock-3.15.3-py3-none-any.whl (16 kB)\n","Using cached fsspec-2024.6.0-py3-none-any.whl (176 kB)\n","Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n","Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n","Using cached sympy-1.12.1-py3-none-any.whl (5.7 MB)\n","Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n","Using cached nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","Installing collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, stable_baselines3\n","Successfully installed MarkupSafe-2.1.5 filelock-3.15.3 fsspec-2024.6.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 stable_baselines3-2.3.2 sympy-1.12.1 torch-2.3.1 triton-2.3.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m笨ｨ沚ｰ笨ｨ Everything looks OK!\n"]}],"source":["!pip install wrds\n","!pip install swig\n","!pip install PyPortfolioOpt\n","!pip install pyfolio-reloaded\n","!pip install -q condacolab\n","!pip install stockstats\n","!pip install gym\n","!pip install gymnasium\n","!pip install stable_baselines3\n","import condacolab\n","condacolab.install()\n","!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":23332,"status":"ok","timestamp":1718875399127,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"W8hwJAqmyiKy"},"outputs":[],"source":["import sys\n","import os\n","import itertools\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.use('Agg')\n","import datetime\n","from plot import backtest_plot, get_baseline, backtest_stats\n","%matplotlib inline\n","from preprocessor.preprocessors import FeatureEngineer, data_split\n","from env.env_stocktrading import StockTradingEnv\n","from models.models import DRLAgent,DRLEnsembleAgent\n","from stable_baselines3.common.logger import configure\n","from stable_baselines3 import A2C, DDPG, PPO\n","\n","from pprint import pprint\n","\n","import itertools"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1718875399128,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"Dr9S-hhhyiKy"},"outputs":[],"source":["from config.config import (\n","    DATA_SAVE_DIR,\n","    TRAINED_MODEL_DIR,\n","    TENSORBOARD_LOG_DIR,\n","    RESULTS_DIR,\n","    INDICATORS,\n","    TRAIN_START_DATE,\n","    TRAIN_END_DATE,\n","    TEST_START_DATE,\n","    TEST_END_DATE,\n","    TRADE_START_DATE,\n","    TRADE_END_DATE,\n","    check_and_make_directories\n",")\n","from config.config_tickers import DOW_30_TICKER\n","\n","check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"]},{"cell_type":"markdown","metadata":{"id":"za0b4ondyiKz"},"source":["# Part 2. Read data\n","\n","We first read the .csv file of our processed data into dataframe."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1402,"status":"ok","timestamp":1718875400522,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"Qv0GyAU6yiK1"},"outputs":[],"source":["processed_data = pd.read_csv(DATA_SAVE_DIR + 'processed_full.csv')\n","processed_data = processed_data.set_index(processed_data.columns[0])\n","processed_data.index.names = ['']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Train date: {TRAIN_START_DATE} - {TRAIN_END_DATE}\")\n","print(f\"Test date: {TEST_START_DATE} - {TEST_END_DATE}\")\n","print(f\"Trade date: {TRADE_START_DATE} - {TRADE_END_DATE}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1718875400540,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"3fGX9a6ymvyu","outputId":"bb526eee-cbc8-4b44-e5ba-7d0b718814ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["29232\n","14500\n"]}],"source":["train = data_split(processed_data, TRAIN_START_DATE,TRAIN_END_DATE)\n","print(len(train))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1718875400540,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"cKx8FjfF57Fq","outputId":"930a4d6d-08c6-46c8-931a-f32f1c15062a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2022-01-01'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["TRAIN_END_DATE"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1718875400540,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"fWHTfl7LyiK2","outputId":"bff4330f-1049-44b9-cff5-523cf4ead332"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"train\",\n  \"rows\": 29232,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2018-01-02\",\n        \"max\": \"2021-12-31\",\n        \"num_unique_values\": 1008,\n        \"samples\": [\n          \"2021-09-23\",\n          \"2020-07-06\",\n          \"2020-09-17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"WBA\",\n          \"KO\",\n          \"IBM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79.58662182539308,\n        \"min\": 27.31999969482422,\n        \"max\": 507.9299926757813,\n        \"num_unique_values\": 18557,\n        \"samples\": [\n          256.25,\n          177.59197998046875,\n          75.18000030517578\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.38495280763027,\n        \"min\": 27.50666618347168,\n        \"max\": 509.2300109863281,\n        \"num_unique_values\": 18863,\n        \"samples\": [\n          221.77999877929688,\n          130.27000427246094,\n          107.0999984741211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78.76987725559054,\n        \"min\": 27.26000022888184,\n        \"max\": 503.6499938964844,\n        \"num_unique_values\": 18828,\n        \"samples\": [\n          54.85686874389648,\n          124.81999969482422,\n          152.1634063720703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76.7154194404829,\n        \"min\": 24.9088191986084,\n        \"max\": 487.7827453613281,\n        \"num_unique_values\": 28428,\n        \"samples\": [\n          61.01531219482422,\n          34.23819732666016,\n          118.07112121582033\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25554482.60164321,\n        \"min\": 405800.0,\n        \"max\": 426510000.0,\n        \"num_unique_values\": 27502,\n        \"samples\": [\n          5257100.0,\n          9882900.0,\n          2710400.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.401098274547636,\n        \"min\": 0.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.0,\n          0.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.876150009388629,\n        \"min\": -56.99468042292054,\n        \"max\": 21.82360994620666,\n        \"num_unique_values\": 29204,\n        \"samples\": [\n          -0.1333702671659864,\n          2.3433399516215587,\n          -1.592649881488697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rsi_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.95166395072721,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 29048,\n        \"samples\": [\n          58.58371466758852,\n          48.51476294485225,\n          62.96158294489047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cci_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111.90080890827755,\n        \"min\": -551.6921709510414,\n        \"max\": 519.905776790741,\n        \"num_unique_values\": 29188,\n        \"samples\": [\n          46.83564846518231,\n          17.52531161753661,\n          90.17834001567998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.263671277569749,\n        \"min\": 0.0010484165616041,\n        \"max\": 100.0,\n        \"num_unique_values\": 28428,\n        \"samples\": [\n          5.115957023711255,\n          12.986740709535024,\n          8.653152412149348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vix\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.888873472689296,\n        \"min\": 9.149999618530272,\n        \"max\": 82.69000244140625,\n        \"num_unique_values\": 770,\n        \"samples\": [\n          17.559999465942383,\n          17.780000686645508,\n          16.40999984741211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"turbulence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.2447612450025,\n        \"min\": 0.0,\n        \"max\": 652.6156008735475,\n        \"num_unique_values\": 755,\n        \"samples\": [\n          63.37079568869853,\n          35.46869578582572,\n          39.3372673939195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"train"},"text/html":["\n","  <div id=\"df-cfec5827-0e29-434d-8c36-54fad4d10058\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>tic</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>day</th>\n","      <th>macd</th>\n","      <th>rsi_30</th>\n","      <th>cci_30</th>\n","      <th>dx_30</th>\n","      <th>vix</th>\n","      <th>turbulence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>AAPL</td>\n","      <td>42.540001</td>\n","      <td>43.075001</td>\n","      <td>42.314999</td>\n","      <td>40.670971</td>\n","      <td>102223600.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>66.666667</td>\n","      <td>100.0</td>\n","      <td>9.77</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>AMGN</td>\n","      <td>175.350006</td>\n","      <td>177.820007</td>\n","      <td>174.419998</td>\n","      <td>146.429108</td>\n","      <td>2301100.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>66.666667</td>\n","      <td>100.0</td>\n","      <td>9.77</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>AXP</td>\n","      <td>99.730003</td>\n","      <td>99.730003</td>\n","      <td>98.220001</td>\n","      <td>90.226944</td>\n","      <td>2746700.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>66.666667</td>\n","      <td>100.0</td>\n","      <td>9.77</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>BA</td>\n","      <td>295.750000</td>\n","      <td>296.989990</td>\n","      <td>295.399994</td>\n","      <td>282.886414</td>\n","      <td>2978900.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>66.666667</td>\n","      <td>100.0</td>\n","      <td>9.77</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>CAT</td>\n","      <td>158.300003</td>\n","      <td>159.389999</td>\n","      <td>156.029999</td>\n","      <td>134.870636</td>\n","      <td>5108400.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>66.666667</td>\n","      <td>100.0</td>\n","      <td>9.77</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfec5827-0e29-434d-8c36-54fad4d10058')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cfec5827-0e29-434d-8c36-54fad4d10058 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cfec5827-0e29-434d-8c36-54fad4d10058');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-26438462-3aa8-47a9-8e22-7e50c1c90b5b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26438462-3aa8-47a9-8e22-7e50c1c90b5b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-26438462-3aa8-47a9-8e22-7e50c1c90b5b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["         date   tic        open        high         low       close  \\\n","0  2018-01-02  AAPL   42.540001   43.075001   42.314999   40.670971   \n","0  2018-01-02  AMGN  175.350006  177.820007  174.419998  146.429108   \n","0  2018-01-02   AXP   99.730003   99.730003   98.220001   90.226944   \n","0  2018-01-02    BA  295.750000  296.989990  295.399994  282.886414   \n","0  2018-01-02   CAT  158.300003  159.389999  156.029999  134.870636   \n","\n","        volume  day  macd  rsi_30     cci_30  dx_30   vix  turbulence  \n","0  102223600.0  1.0   0.0     0.0  66.666667  100.0  9.77         0.0  \n","0    2301100.0  1.0   0.0     0.0  66.666667  100.0  9.77         0.0  \n","0    2746700.0  1.0   0.0     0.0  66.666667  100.0  9.77         0.0  \n","0    2978900.0  1.0   0.0     0.0  66.666667  100.0  9.77         0.0  \n","0    5108400.0  1.0   0.0     0.0  66.666667  100.0  9.77         0.0  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1718875400540,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"vr6XbDl9yiK2","outputId":"0e1f852f-bb94-4224-d17c-8391da48bd6f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"repr_error":"0","type":"dataframe"},"text/html":["\n","  <div id=\"df-a1246a3d-caa2-4de2-bbbf-24a38cc3143e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>tic</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>day</th>\n","      <th>macd</th>\n","      <th>rsi_30</th>\n","      <th>cci_30</th>\n","      <th>dx_30</th>\n","      <th>vix</th>\n","      <th>turbulence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>UNH</td>\n","      <td>504.140015</td>\n","      <td>506.869995</td>\n","      <td>502.040009</td>\n","      <td>484.463928</td>\n","      <td>1695400.0</td>\n","      <td>4.0</td>\n","      <td>12.928914</td>\n","      <td>66.917702</td>\n","      <td>105.219094</td>\n","      <td>35.524631</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>V</td>\n","      <td>216.809998</td>\n","      <td>217.979996</td>\n","      <td>215.490005</td>\n","      <td>212.991302</td>\n","      <td>4723300.0</td>\n","      <td>4.0</td>\n","      <td>2.616086</td>\n","      <td>51.608553</td>\n","      <td>86.144479</td>\n","      <td>0.410017</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>VZ</td>\n","      <td>52.200001</td>\n","      <td>52.310001</td>\n","      <td>51.880001</td>\n","      <td>44.412312</td>\n","      <td>15911400.0</td>\n","      <td>4.0</td>\n","      <td>0.200583</td>\n","      <td>48.646226</td>\n","      <td>41.490886</td>\n","      <td>10.681208</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>WBA</td>\n","      <td>51.900002</td>\n","      <td>52.419998</td>\n","      <td>51.830002</td>\n","      <td>45.353912</td>\n","      <td>3406700.0</td>\n","      <td>4.0</td>\n","      <td>0.966713</td>\n","      <td>60.665078</td>\n","      <td>137.655018</td>\n","      <td>25.778533</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>WMT</td>\n","      <td>47.733334</td>\n","      <td>48.346668</td>\n","      <td>47.639999</td>\n","      <td>46.611462</td>\n","      <td>17947800.0</td>\n","      <td>4.0</td>\n","      <td>0.035970</td>\n","      <td>52.959531</td>\n","      <td>77.948767</td>\n","      <td>1.606327</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1246a3d-caa2-4de2-bbbf-24a38cc3143e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a1246a3d-caa2-4de2-bbbf-24a38cc3143e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a1246a3d-caa2-4de2-bbbf-24a38cc3143e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5c3d0555-5999-4534-82ed-56e94994d7c2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c3d0555-5999-4534-82ed-56e94994d7c2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5c3d0555-5999-4534-82ed-56e94994d7c2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["            date  tic        open        high         low       close  \\\n","1007  2021-12-31  UNH  504.140015  506.869995  502.040009  484.463928   \n","1007  2021-12-31    V  216.809998  217.979996  215.490005  212.991302   \n","1007  2021-12-31   VZ   52.200001   52.310001   51.880001   44.412312   \n","1007  2021-12-31  WBA   51.900002   52.419998   51.830002   45.353912   \n","1007  2021-12-31  WMT   47.733334   48.346668   47.639999   46.611462   \n","\n","          volume  day       macd     rsi_30      cci_30      dx_30        vix  \\\n","1007   1695400.0  4.0  12.928914  66.917702  105.219094  35.524631  17.219999   \n","1007   4723300.0  4.0   2.616086  51.608553   86.144479   0.410017  17.219999   \n","1007  15911400.0  4.0   0.200583  48.646226   41.490886  10.681208  17.219999   \n","1007   3406700.0  4.0   0.966713  60.665078  137.655018  25.778533  17.219999   \n","1007  17947800.0  4.0   0.035970  52.959531   77.948767   1.606327  17.219999   \n","\n","      turbulence  \n","1007   12.137917  \n","1007   12.137917  \n","1007   12.137917  \n","1007   12.137917  \n","1007   12.137917  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train.tail()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1718875400541,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"TmvuyTD-yiK3","outputId":"7c9f0cdf-f503-4058-a6f9-71bccfe8c07e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"trade\",\n  \"rows\": 14500,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-01-03\",\n        \"max\": \"2023-12-28\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"2023-06-12\",\n          \"2022-04-19\",\n          \"2023-06-30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"WBA\",\n          \"KO\",\n          \"IBM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.0181779321121,\n        \"min\": 19.950000762939453,\n        \"max\": 555.0,\n        \"num_unique_values\": 11254,\n        \"samples\": [\n          104.81999969482422,\n          62.83000183105469,\n          178.8800048828125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.06314553741433,\n        \"min\": 20.11000061035156,\n        \"max\": 558.0999755859375,\n        \"num_unique_values\": 11507,\n        \"samples\": [\n          273.57000732421875,\n          29.82999992370605,\n          51.09000015258789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 103.97215319659529,\n        \"min\": 19.68000030517578,\n        \"max\": 550.1300048828125,\n        \"num_unique_values\": 11396,\n        \"samples\": [\n          251.00999450683597,\n          209.3000030517578,\n          51.63999938964844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 102.72426612803783,\n        \"min\": 19.44523048400879,\n        \"max\": 546.607177734375,\n        \"num_unique_values\": 14138,\n        \"samples\": [\n          180.96673583984372,\n          151.14707946777344,\n          42.842872619628906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16593034.600975065,\n        \"min\": 416700.0,\n        \"max\": 182602000.0,\n        \"num_unique_values\": 13886,\n        \"samples\": [\n          35195900.0,\n          1674800.0,\n          10726200.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3915349592184443,\n        \"min\": 0.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          4.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.343359219012434,\n        \"min\": -14.44404193967756,\n        \"max\": 16.24762225904618,\n        \"num_unique_values\": 14500,\n        \"samples\": [\n          1.1515374571515338,\n          3.799239388714796,\n          -0.1776595925610422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rsi_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.140672593532505,\n        \"min\": 24.33543650691719,\n        \"max\": 80.42306360453951,\n        \"num_unique_values\": 14465,\n        \"samples\": [\n          53.79101999971861,\n          43.060638091907926,\n          57.15040246397319\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cci_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 113.14102183353477,\n        \"min\": -428.7248498213846,\n        \"max\": 415.51397192663705,\n        \"num_unique_values\": 14500,\n        \"samples\": [\n          47.731417619456536,\n          36.05047025348851,\n          -4.809131356336695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.232380984181868,\n        \"min\": 0.001437839138288,\n        \"max\": 62.96818565059459,\n        \"num_unique_values\": 14198,\n        \"samples\": [\n          9.14425419282005,\n          16.214702835986888,\n          9.056803001482672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vix\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.730160351788748,\n        \"min\": 12.06999969482422,\n        \"max\": 36.45000076293945,\n        \"num_unique_values\": 437,\n        \"samples\": [\n          17.8799991607666,\n          31.600000381469727,\n          18.399999618530277\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"turbulence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.07913957572903,\n        \"min\": 4.534653928717222,\n        \"max\": 290.7862277823189,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          18.209085058129524,\n          84.51589075368076,\n          21.70628877498678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"trade"},"text/html":["\n","  <div id=\"df-383a6dbb-62ae-41e3-be4c-7ddbccac842f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>tic</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>day</th>\n","      <th>macd</th>\n","      <th>rsi_30</th>\n","      <th>cci_30</th>\n","      <th>dx_30</th>\n","      <th>vix</th>\n","      <th>turbulence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-01-03</td>\n","      <td>AAPL</td>\n","      <td>177.830002</td>\n","      <td>182.880005</td>\n","      <td>177.710007</td>\n","      <td>179.724533</td>\n","      <td>104487900.0</td>\n","      <td>0.0</td>\n","      <td>4.767874</td>\n","      <td>64.844852</td>\n","      <td>102.677577</td>\n","      <td>42.087725</td>\n","      <td>16.6</td>\n","      <td>40.628291</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-01-03</td>\n","      <td>AMGN</td>\n","      <td>223.630005</td>\n","      <td>226.970001</td>\n","      <td>222.029999</td>\n","      <td>210.740341</td>\n","      <td>2742800.0</td>\n","      <td>0.0</td>\n","      <td>4.504905</td>\n","      <td>60.592151</td>\n","      <td>90.703115</td>\n","      <td>20.989652</td>\n","      <td>16.6</td>\n","      <td>40.628291</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-01-03</td>\n","      <td>AXP</td>\n","      <td>164.509995</td>\n","      <td>168.399994</td>\n","      <td>164.399994</td>\n","      <td>162.605331</td>\n","      <td>3236400.0</td>\n","      <td>0.0</td>\n","      <td>-0.638614</td>\n","      <td>50.972514</td>\n","      <td>59.310205</td>\n","      <td>1.754196</td>\n","      <td>16.6</td>\n","      <td>40.628291</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-01-03</td>\n","      <td>BA</td>\n","      <td>204.000000</td>\n","      <td>210.550003</td>\n","      <td>203.339996</td>\n","      <td>207.860001</td>\n","      <td>9060200.0</td>\n","      <td>0.0</td>\n","      <td>-0.982440</td>\n","      <td>49.747896</td>\n","      <td>65.232126</td>\n","      <td>3.639708</td>\n","      <td>16.6</td>\n","      <td>40.628291</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-01-03</td>\n","      <td>CAT</td>\n","      <td>207.330002</td>\n","      <td>208.600006</td>\n","      <td>205.800003</td>\n","      <td>196.558151</td>\n","      <td>2055600.0</td>\n","      <td>0.0</td>\n","      <td>1.291196</td>\n","      <td>53.031031</td>\n","      <td>98.541070</td>\n","      <td>6.201519</td>\n","      <td>16.6</td>\n","      <td>40.628291</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-383a6dbb-62ae-41e3-be4c-7ddbccac842f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-383a6dbb-62ae-41e3-be4c-7ddbccac842f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-383a6dbb-62ae-41e3-be4c-7ddbccac842f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a84bad3c-c571-4b53-a88a-19c369f9e16f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a84bad3c-c571-4b53-a88a-19c369f9e16f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a84bad3c-c571-4b53-a88a-19c369f9e16f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["         date   tic        open        high         low       close  \\\n","0  2022-01-03  AAPL  177.830002  182.880005  177.710007  179.724533   \n","0  2022-01-03  AMGN  223.630005  226.970001  222.029999  210.740341   \n","0  2022-01-03   AXP  164.509995  168.399994  164.399994  162.605331   \n","0  2022-01-03    BA  204.000000  210.550003  203.339996  207.860001   \n","0  2022-01-03   CAT  207.330002  208.600006  205.800003  196.558151   \n","\n","        volume  day      macd     rsi_30      cci_30      dx_30   vix  \\\n","0  104487900.0  0.0  4.767874  64.844852  102.677577  42.087725  16.6   \n","0    2742800.0  0.0  4.504905  60.592151   90.703115  20.989652  16.6   \n","0    3236400.0  0.0 -0.638614  50.972514   59.310205   1.754196  16.6   \n","0    9060200.0  0.0 -0.982440  49.747896   65.232126   3.639708  16.6   \n","0    2055600.0  0.0  1.291196  53.031031   98.541070   6.201519  16.6   \n","\n","   turbulence  \n","0   40.628291  \n","0   40.628291  \n","0   40.628291  \n","0   40.628291  \n","0   40.628291  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["trade.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1718875400541,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"EJdjL9tEyiK3","outputId":"22a4dae0-326c-482e-9b06-1e8907400a46"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"repr_error":"0","type":"dataframe"},"text/html":["\n","  <div id=\"df-9ff0b923-8e23-447e-89ee-4067e62cef83\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>tic</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>day</th>\n","      <th>macd</th>\n","      <th>rsi_30</th>\n","      <th>cci_30</th>\n","      <th>dx_30</th>\n","      <th>vix</th>\n","      <th>turbulence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>499</th>\n","      <td>2023-12-28</td>\n","      <td>UNH</td>\n","      <td>523.469971</td>\n","      <td>527.869995</td>\n","      <td>522.940002</td>\n","      <td>520.630310</td>\n","      <td>2001000.0</td>\n","      <td>3.0</td>\n","      <td>-4.482944</td>\n","      <td>48.544493</td>\n","      <td>-86.554479</td>\n","      <td>9.418188</td>\n","      <td>12.47</td>\n","      <td>7.060585</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>2023-12-28</td>\n","      <td>V</td>\n","      <td>258.540009</td>\n","      <td>260.970001</td>\n","      <td>258.540009</td>\n","      <td>259.915344</td>\n","      <td>3020500.0</td>\n","      <td>3.0</td>\n","      <td>2.767469</td>\n","      <td>61.502711</td>\n","      <td>102.513885</td>\n","      <td>26.012559</td>\n","      <td>12.47</td>\n","      <td>7.060585</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>2023-12-28</td>\n","      <td>VZ</td>\n","      <td>37.180000</td>\n","      <td>37.720001</td>\n","      <td>37.150002</td>\n","      <td>36.280758</td>\n","      <td>14931700.0</td>\n","      <td>3.0</td>\n","      <td>0.248021</td>\n","      <td>57.521271</td>\n","      <td>-7.145725</td>\n","      <td>15.051402</td>\n","      <td>12.47</td>\n","      <td>7.060585</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>2023-12-28</td>\n","      <td>WBA</td>\n","      <td>26.590000</td>\n","      <td>27.020000</td>\n","      <td>26.389999</td>\n","      <td>25.939976</td>\n","      <td>7899900.0</td>\n","      <td>3.0</td>\n","      <td>1.399880</td>\n","      <td>64.322401</td>\n","      <td>118.533676</td>\n","      <td>35.833180</td>\n","      <td>12.47</td>\n","      <td>7.060585</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>2023-12-28</td>\n","      <td>WMT</td>\n","      <td>52.590000</td>\n","      <td>52.776669</td>\n","      <td>52.500000</td>\n","      <td>52.345058</td>\n","      <td>16776000.0</td>\n","      <td>3.0</td>\n","      <td>-0.069524</td>\n","      <td>50.536042</td>\n","      <td>89.737088</td>\n","      <td>0.984013</td>\n","      <td>12.47</td>\n","      <td>7.060585</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ff0b923-8e23-447e-89ee-4067e62cef83')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9ff0b923-8e23-447e-89ee-4067e62cef83 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9ff0b923-8e23-447e-89ee-4067e62cef83');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-089fb984-6f2f-4a82-b94f-0153a091d35d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-089fb984-6f2f-4a82-b94f-0153a091d35d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-089fb984-6f2f-4a82-b94f-0153a091d35d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["           date  tic        open        high         low       close  \\\n","499  2023-12-28  UNH  523.469971  527.869995  522.940002  520.630310   \n","499  2023-12-28    V  258.540009  260.970001  258.540009  259.915344   \n","499  2023-12-28   VZ   37.180000   37.720001   37.150002   36.280758   \n","499  2023-12-28  WBA   26.590000   27.020000   26.389999   25.939976   \n","499  2023-12-28  WMT   52.590000   52.776669   52.500000   52.345058   \n","\n","         volume  day      macd     rsi_30      cci_30      dx_30    vix  \\\n","499   2001000.0  3.0 -4.482944  48.544493  -86.554479   9.418188  12.47   \n","499   3020500.0  3.0  2.767469  61.502711  102.513885  26.012559  12.47   \n","499  14931700.0  3.0  0.248021  57.521271   -7.145725  15.051402  12.47   \n","499   7899900.0  3.0  1.399880  64.322401  118.533676  35.833180  12.47   \n","499  16776000.0  3.0 -0.069524  50.536042   89.737088   0.984013  12.47   \n","\n","     turbulence  \n","499    7.060585  \n","499    7.060585  \n","499    7.060585  \n","499    7.060585  \n","499    7.060585  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["trade.tail()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":598,"status":"ok","timestamp":1718875401106,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"F_C1MrsZyiK4","outputId":"b754edbc-c069-4598-e1f1-8fde9aaaa40b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train shape: (29232, 14)\n","Trade shape: (14500, 14)\n"]}],"source":["print(f\"Train shape: {train.shape}\")\n","print(f\"Trade shape: {trade.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"MJ7vpD24yiK4"},"source":["# Part 3. Construct the environment"]},{"cell_type":"markdown","metadata":{"id":"LqF5RPs_yiK4"},"source":["Calculate and specify the parameters we need for constructing the environment."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1718875401107,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"KJlR4E3cyiK5"},"outputs":[],"source":["INDICATORS = ['macd',\n","            'rsi_30',\n","            'cci_30',\n","            'dx_30']"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1718875401107,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"ajZ_0LYEyiK5","outputId":"b889f1b6-ddde-4667-8584-7642b46dd877"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stock Dimension: 29, State Space: 175\n"]}],"source":["stock_dimension = len(train.tic.unique())\n","state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n","print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1718875401107,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"03-nyXneyiK5","outputId":"0d02c570-9284-4375-8185-8b9eaf651c99"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"train\",\n  \"rows\": 29232,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2018-01-02\",\n        \"max\": \"2021-12-31\",\n        \"num_unique_values\": 1008,\n        \"samples\": [\n          \"2021-09-23\",\n          \"2020-07-06\",\n          \"2020-09-17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"WBA\",\n          \"KO\",\n          \"IBM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79.58662182539308,\n        \"min\": 27.31999969482422,\n        \"max\": 507.9299926757813,\n        \"num_unique_values\": 18557,\n        \"samples\": [\n          256.25,\n          177.59197998046875,\n          75.18000030517578\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.38495280763027,\n        \"min\": 27.50666618347168,\n        \"max\": 509.2300109863281,\n        \"num_unique_values\": 18863,\n        \"samples\": [\n          221.77999877929688,\n          130.27000427246094,\n          107.0999984741211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78.76987725559054,\n        \"min\": 27.26000022888184,\n        \"max\": 503.6499938964844,\n        \"num_unique_values\": 18828,\n        \"samples\": [\n          54.85686874389648,\n          124.81999969482422,\n          152.1634063720703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76.7154194404829,\n        \"min\": 24.9088191986084,\n        \"max\": 487.7827453613281,\n        \"num_unique_values\": 28428,\n        \"samples\": [\n          61.01531219482422,\n          34.23819732666016,\n          118.07112121582033\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25554482.60164321,\n        \"min\": 405800.0,\n        \"max\": 426510000.0,\n        \"num_unique_values\": 27502,\n        \"samples\": [\n          5257100.0,\n          9882900.0,\n          2710400.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.401098274547636,\n        \"min\": 0.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.0,\n          0.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.876150009388629,\n        \"min\": -56.99468042292054,\n        \"max\": 21.82360994620666,\n        \"num_unique_values\": 29204,\n        \"samples\": [\n          -0.1333702671659864,\n          2.3433399516215587,\n          -1.592649881488697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rsi_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.95166395072721,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 29048,\n        \"samples\": [\n          58.58371466758852,\n          48.51476294485225,\n          62.96158294489047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cci_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111.90080890827755,\n        \"min\": -551.6921709510414,\n        \"max\": 519.905776790741,\n        \"num_unique_values\": 29188,\n        \"samples\": [\n          46.83564846518231,\n          17.52531161753661,\n          90.17834001567998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.263671277569749,\n        \"min\": 0.0010484165616041,\n        \"max\": 100.0,\n        \"num_unique_values\": 28428,\n        \"samples\": [\n          5.115957023711255,\n          12.986740709535024,\n          8.653152412149348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vix\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.888873472689296,\n        \"min\": 9.149999618530272,\n        \"max\": 82.69000244140625,\n        \"num_unique_values\": 770,\n        \"samples\": [\n          17.559999465942383,\n          17.780000686645508,\n          16.40999984741211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"turbulence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.2447612450025,\n        \"min\": 0.0,\n        \"max\": 652.6156008735475,\n        \"num_unique_values\": 755,\n        \"samples\": [\n          63.37079568869853,\n          35.46869578582572,\n          39.3372673939195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"train"},"text/html":["\n","  <div id=\"df-01b988a6-666d-428d-bdee-c3c0a4907727\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>tic</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>day</th>\n","      <th>macd</th>\n","      <th>rsi_30</th>\n","      <th>cci_30</th>\n","      <th>dx_30</th>\n","      <th>vix</th>\n","      <th>turbulence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>AAPL</td>\n","      <td>42.540001</td>\n","      <td>43.075001</td>\n","      <td>42.314999</td>\n","      <td>40.670971</td>\n","      <td>102223600.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>66.666667</td>\n","      <td>100.000000</td>\n","      <td>9.770000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>AMGN</td>\n","      <td>175.350006</td>\n","      <td>177.820007</td>\n","      <td>174.419998</td>\n","      <td>146.429108</td>\n","      <td>2301100.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>66.666667</td>\n","      <td>100.000000</td>\n","      <td>9.770000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>AXP</td>\n","      <td>99.730003</td>\n","      <td>99.730003</td>\n","      <td>98.220001</td>\n","      <td>90.226944</td>\n","      <td>2746700.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>66.666667</td>\n","      <td>100.000000</td>\n","      <td>9.770000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>BA</td>\n","      <td>295.750000</td>\n","      <td>296.989990</td>\n","      <td>295.399994</td>\n","      <td>282.886414</td>\n","      <td>2978900.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>66.666667</td>\n","      <td>100.000000</td>\n","      <td>9.770000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02</td>\n","      <td>CAT</td>\n","      <td>158.300003</td>\n","      <td>159.389999</td>\n","      <td>156.029999</td>\n","      <td>134.870636</td>\n","      <td>5108400.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>66.666667</td>\n","      <td>100.000000</td>\n","      <td>9.770000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>UNH</td>\n","      <td>504.140015</td>\n","      <td>506.869995</td>\n","      <td>502.040009</td>\n","      <td>484.463928</td>\n","      <td>1695400.0</td>\n","      <td>4.0</td>\n","      <td>12.928914</td>\n","      <td>66.917702</td>\n","      <td>105.219094</td>\n","      <td>35.524631</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>V</td>\n","      <td>216.809998</td>\n","      <td>217.979996</td>\n","      <td>215.490005</td>\n","      <td>212.991302</td>\n","      <td>4723300.0</td>\n","      <td>4.0</td>\n","      <td>2.616086</td>\n","      <td>51.608553</td>\n","      <td>86.144479</td>\n","      <td>0.410017</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>VZ</td>\n","      <td>52.200001</td>\n","      <td>52.310001</td>\n","      <td>51.880001</td>\n","      <td>44.412312</td>\n","      <td>15911400.0</td>\n","      <td>4.0</td>\n","      <td>0.200583</td>\n","      <td>48.646226</td>\n","      <td>41.490886</td>\n","      <td>10.681208</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>WBA</td>\n","      <td>51.900002</td>\n","      <td>52.419998</td>\n","      <td>51.830002</td>\n","      <td>45.353912</td>\n","      <td>3406700.0</td>\n","      <td>4.0</td>\n","      <td>0.966713</td>\n","      <td>60.665078</td>\n","      <td>137.655018</td>\n","      <td>25.778533</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>2021-12-31</td>\n","      <td>WMT</td>\n","      <td>47.733334</td>\n","      <td>48.346668</td>\n","      <td>47.639999</td>\n","      <td>46.611462</td>\n","      <td>17947800.0</td>\n","      <td>4.0</td>\n","      <td>0.035970</td>\n","      <td>52.959531</td>\n","      <td>77.948767</td>\n","      <td>1.606327</td>\n","      <td>17.219999</td>\n","      <td>12.137917</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>29232 rows ﾃ 14 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01b988a6-666d-428d-bdee-c3c0a4907727')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-01b988a6-666d-428d-bdee-c3c0a4907727 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-01b988a6-666d-428d-bdee-c3c0a4907727');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2b7e95f0-ce12-48a3-a788-66e394238a7b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b7e95f0-ce12-48a3-a788-66e394238a7b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2b7e95f0-ce12-48a3-a788-66e394238a7b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_68346b7a-d789-4ce5-a248-480da958577e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_68346b7a-d789-4ce5-a248-480da958577e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('train');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["            date   tic        open        high         low       close  \\\n","0     2018-01-02  AAPL   42.540001   43.075001   42.314999   40.670971   \n","0     2018-01-02  AMGN  175.350006  177.820007  174.419998  146.429108   \n","0     2018-01-02   AXP   99.730003   99.730003   98.220001   90.226944   \n","0     2018-01-02    BA  295.750000  296.989990  295.399994  282.886414   \n","0     2018-01-02   CAT  158.300003  159.389999  156.029999  134.870636   \n","...          ...   ...         ...         ...         ...         ...   \n","1007  2021-12-31   UNH  504.140015  506.869995  502.040009  484.463928   \n","1007  2021-12-31     V  216.809998  217.979996  215.490005  212.991302   \n","1007  2021-12-31    VZ   52.200001   52.310001   51.880001   44.412312   \n","1007  2021-12-31   WBA   51.900002   52.419998   51.830002   45.353912   \n","1007  2021-12-31   WMT   47.733334   48.346668   47.639999   46.611462   \n","\n","           volume  day       macd     rsi_30      cci_30       dx_30  \\\n","0     102223600.0  1.0   0.000000   0.000000   66.666667  100.000000   \n","0       2301100.0  1.0   0.000000   0.000000   66.666667  100.000000   \n","0       2746700.0  1.0   0.000000   0.000000   66.666667  100.000000   \n","0       2978900.0  1.0   0.000000   0.000000   66.666667  100.000000   \n","0       5108400.0  1.0   0.000000   0.000000   66.666667  100.000000   \n","...           ...  ...        ...        ...         ...         ...   \n","1007    1695400.0  4.0  12.928914  66.917702  105.219094   35.524631   \n","1007    4723300.0  4.0   2.616086  51.608553   86.144479    0.410017   \n","1007   15911400.0  4.0   0.200583  48.646226   41.490886   10.681208   \n","1007    3406700.0  4.0   0.966713  60.665078  137.655018   25.778533   \n","1007   17947800.0  4.0   0.035970  52.959531   77.948767    1.606327   \n","\n","            vix  turbulence  \n","0      9.770000    0.000000  \n","0      9.770000    0.000000  \n","0      9.770000    0.000000  \n","0      9.770000    0.000000  \n","0      9.770000    0.000000  \n","...         ...         ...  \n","1007  17.219999   12.137917  \n","1007  17.219999   12.137917  \n","1007  17.219999   12.137917  \n","1007  17.219999   12.137917  \n","1007  17.219999   12.137917  \n","\n","[29232 rows x 14 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1718875401108,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"Ju3GS6hAyiK6"},"outputs":[],"source":["buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n","num_stock_shares = [0] * stock_dimension\n","\n","env_kwargs = {\n","    \"hmax\": 100,\n","    \"initial_amount\": 1000000,\n","    \"num_stock_shares\": num_stock_shares,\n","    \"buy_cost_pct\": buy_cost_list,\n","    \"sell_cost_pct\": sell_cost_list,\n","    \"state_space\": state_space,\n","    \"stock_dim\": stock_dimension,\n","    \"tech_indicator_list\": INDICATORS,\n","    \"action_space\": stock_dimension,\n","    \"reward_scaling\": 1e-4\n","}\n","\n","e_train_gym = StockTradingEnv(df = train, **env_kwargs)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1718875401108,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"0r5XCWh_yiK6","outputId":"14e3fa7c-4b10-492e-a44d-03aa8df11359"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"]}],"source":["env_train, _ = e_train_gym.get_sb_env()\n","print(type(env_train))"]},{"cell_type":"markdown","metadata":{"id":"3hpTNtMyyiK6"},"source":["# Part 4. Train DRL Agents"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1718875401108,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"-4y8yyBTyiK7"},"outputs":[],"source":["agent = DRLAgent(env = env_train)\n","\n","# Set the corresponding values to 'True' for the algorithms that you want to use\n","if_using_a2c = True\n","if_using_ddpg = True\n","if_using_ppo = True\n","if_using_ensemble = True"]},{"cell_type":"markdown","metadata":{"id":"JSb1iz1ryiK7"},"source":["### Agent 1: A2C"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2986,"status":"ok","timestamp":1718875404074,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"t98AV-wYyiK7","outputId":"17d4209a-aba9-487a-e6d8-dc5e6e6dc555"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n","Using cuda device\n","Logging to results/a2c\n"]}],"source":["agent = DRLAgent(env = env_train)\n","model_a2c = agent.get_model(\"a2c\")\n","\n","if if_using_a2c:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + 'a2c'\n","  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_a2c.set_logger(new_logger_a2c)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136566,"status":"ok","timestamp":1718875540633,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"wK-0kRwFyiK7","outputId":"b0d1ab0b-e61a-4f60-e6ae-3e1be17107c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------------------------------\n","| time/                 |             |\n","|    fps                | 65          |\n","|    iterations         | 100         |\n","|    time_elapsed       | 7           |\n","|    total_timesteps    | 500         |\n","| train/                |             |\n","|    entropy_loss       | -41.2       |\n","|    explained_variance | 0.698       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 99          |\n","|    policy_loss        | 23.1        |\n","|    reward             | 0.024734754 |\n","|    std                | 1           |\n","|    value_loss         | 0.341       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 70        |\n","|    iterations         | 200       |\n","|    time_elapsed       | 14        |\n","|    total_timesteps    | 1000      |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | 0.243     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 199       |\n","|    policy_loss        | -161      |\n","|    reward             | 3.3148546 |\n","|    std                | 1         |\n","|    value_loss         | 14.7      |\n","-------------------------------------\n","Episode: 2\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 87         |\n","|    iterations         | 300        |\n","|    time_elapsed       | 17         |\n","|    total_timesteps    | 1500       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -0.0771    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 299        |\n","|    policy_loss        | -0.283     |\n","|    reward             | 0.48235127 |\n","|    std                | 1          |\n","|    value_loss         | 0.178      |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 99          |\n","|    iterations         | 400         |\n","|    time_elapsed       | 20          |\n","|    total_timesteps    | 2000        |\n","| train/                |             |\n","|    entropy_loss       | -41.2       |\n","|    explained_variance | -0.0241     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 399         |\n","|    policy_loss        | -155        |\n","|    reward             | -0.93500715 |\n","|    std                | 1           |\n","|    value_loss         | 42.3        |\n","---------------------------------------\n","Episode: 3\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 106         |\n","|    iterations         | 500         |\n","|    time_elapsed       | 23          |\n","|    total_timesteps    | 2500        |\n","| train/                |             |\n","|    entropy_loss       | -41.2       |\n","|    explained_variance | 0.0324      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 499         |\n","|    policy_loss        | 17.7        |\n","|    reward             | -0.04014676 |\n","|    std                | 1           |\n","|    value_loss         | 0.294       |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 110         |\n","|    iterations         | 600         |\n","|    time_elapsed       | 27          |\n","|    total_timesteps    | 3000        |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | -1.19e-07   |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 599         |\n","|    policy_loss        | -150        |\n","|    reward             | -0.98244905 |\n","|    std                | 1.01        |\n","|    value_loss         | 14.5        |\n","---------------------------------------\n","Episode: 4\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 116         |\n","|    iterations         | 700         |\n","|    time_elapsed       | 30          |\n","|    total_timesteps    | 3500        |\n","| train/                |             |\n","|    entropy_loss       | -41.4       |\n","|    explained_variance | -0.0583     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 699         |\n","|    policy_loss        | 36.6        |\n","|    reward             | -0.80469394 |\n","|    std                | 1.01        |\n","|    value_loss         | 0.939       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 121       |\n","|    iterations         | 800       |\n","|    time_elapsed       | 32        |\n","|    total_timesteps    | 4000      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0.0669    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 799       |\n","|    policy_loss        | -10.9     |\n","|    reward             | -2.543988 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.584     |\n","-------------------------------------\n","Episode: 5\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 126        |\n","|    iterations         | 900        |\n","|    time_elapsed       | 35         |\n","|    total_timesteps    | 4500       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 899        |\n","|    policy_loss        | -27.2      |\n","|    reward             | 0.74579364 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.701      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 125       |\n","|    iterations         | 1000      |\n","|    time_elapsed       | 39        |\n","|    total_timesteps    | 5000      |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0.000168  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 999       |\n","|    policy_loss        | 34.4      |\n","|    reward             | 1.2294321 |\n","|    std                | 1.01      |\n","|    value_loss         | 1.46      |\n","-------------------------------------\n","Episode: 6\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 128       |\n","|    iterations         | 1100      |\n","|    time_elapsed       | 42        |\n","|    total_timesteps    | 5500      |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0.249     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1099      |\n","|    policy_loss        | -2.34     |\n","|    reward             | 1.3224238 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.183     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 131        |\n","|    iterations         | 1200       |\n","|    time_elapsed       | 45         |\n","|    total_timesteps    | 6000       |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1199       |\n","|    policy_loss        | 48.9       |\n","|    reward             | 0.49920002 |\n","|    std                | 1.01       |\n","|    value_loss         | 3.45       |\n","--------------------------------------\n","Episode: 7\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 1300       |\n","|    time_elapsed       | 48         |\n","|    total_timesteps    | 6500       |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1299       |\n","|    policy_loss        | 40.1       |\n","|    reward             | -0.4899588 |\n","|    std                | 1.01       |\n","|    value_loss         | 1.46       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 134         |\n","|    iterations         | 1400        |\n","|    time_elapsed       | 52          |\n","|    total_timesteps    | 7000        |\n","| train/                |             |\n","|    entropy_loss       | -41.6       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1399        |\n","|    policy_loss        | -0.0273     |\n","|    reward             | -0.65674454 |\n","|    std                | 1.02        |\n","|    value_loss         | 3.29        |\n","---------------------------------------\n","Episode: 8\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 134       |\n","|    iterations         | 1500      |\n","|    time_elapsed       | 55        |\n","|    total_timesteps    | 7500      |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1499      |\n","|    policy_loss        | -54.8     |\n","|    reward             | -0.752815 |\n","|    std                | 1.02      |\n","|    value_loss         | 1.87      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 136       |\n","|    iterations         | 1600      |\n","|    time_elapsed       | 58        |\n","|    total_timesteps    | 8000      |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1599      |\n","|    policy_loss        | 28.2      |\n","|    reward             | -0.937482 |\n","|    std                | 1.02      |\n","|    value_loss         | 1.24      |\n","-------------------------------------\n","Episode: 9\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 1700        |\n","|    time_elapsed       | 61          |\n","|    total_timesteps    | 8500        |\n","| train/                |             |\n","|    entropy_loss       | -41.7       |\n","|    explained_variance | 1.19e-07    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1699        |\n","|    policy_loss        | -0.139      |\n","|    reward             | -0.15996955 |\n","|    std                | 1.02        |\n","|    value_loss         | 0.563       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 139       |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 64        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | -79.9     |\n","|    reward             | 0.4125586 |\n","|    std                | 1.02      |\n","|    value_loss         | 3.78      |\n","-------------------------------------\n","Episode: 10\n","day: 1007, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 1664711.45\n","total_reward: 664711.45\n","total_cost: 8021.28\n","total_trades: 15237\n","Sharpe: 0.772\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 138       |\n","|    iterations         | 1900      |\n","|    time_elapsed       | 68        |\n","|    total_timesteps    | 9500      |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1899      |\n","|    policy_loss        | -4.62     |\n","|    reward             | -1.440481 |\n","|    std                | 1.02      |\n","|    value_loss         | 0.179     |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 139         |\n","|    iterations         | 2000        |\n","|    time_elapsed       | 71          |\n","|    total_timesteps    | 10000       |\n","| train/                |             |\n","|    entropy_loss       | -41.7       |\n","|    explained_variance | 1.19e-07    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1999        |\n","|    policy_loss        | 15.5        |\n","|    reward             | -0.74723256 |\n","|    std                | 1.02        |\n","|    value_loss         | 0.378       |\n","---------------------------------------\n","Episode: 11\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 141       |\n","|    iterations         | 2100      |\n","|    time_elapsed       | 74        |\n","|    total_timesteps    | 10500     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0.0116    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2099      |\n","|    policy_loss        | 6.47      |\n","|    reward             | 1.1416093 |\n","|    std                | 1.02      |\n","|    value_loss         | 0.601     |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 141         |\n","|    iterations         | 2200        |\n","|    time_elapsed       | 77          |\n","|    total_timesteps    | 11000       |\n","| train/                |             |\n","|    entropy_loss       | -41.8       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2199        |\n","|    policy_loss        | -4.82       |\n","|    reward             | -0.14034447 |\n","|    std                | 1.02        |\n","|    value_loss         | 1.7         |\n","---------------------------------------\n","Episode: 12\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 140         |\n","|    iterations         | 2300        |\n","|    time_elapsed       | 82          |\n","|    total_timesteps    | 11500       |\n","| train/                |             |\n","|    entropy_loss       | -41.8       |\n","|    explained_variance | -0.0277     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2299        |\n","|    policy_loss        | 34.9        |\n","|    reward             | -0.16325924 |\n","|    std                | 1.02        |\n","|    value_loss         | 2.15        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 140       |\n","|    iterations         | 2400      |\n","|    time_elapsed       | 85        |\n","|    total_timesteps    | 12000     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0.0168    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2399      |\n","|    policy_loss        | 30.8      |\n","|    reward             | -0.893642 |\n","|    std                | 1.02      |\n","|    value_loss         | 0.92      |\n","-------------------------------------\n","Episode: 13\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 142        |\n","|    iterations         | 2500       |\n","|    time_elapsed       | 88         |\n","|    total_timesteps    | 12500      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | -0.91      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2499       |\n","|    policy_loss        | -138       |\n","|    reward             | -0.8958161 |\n","|    std                | 1.02       |\n","|    value_loss         | 14.3       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 143       |\n","|    iterations         | 2600      |\n","|    time_elapsed       | 90        |\n","|    total_timesteps    | 13000     |\n","| train/                |           |\n","|    entropy_loss       | -41.8     |\n","|    explained_variance | -0.239    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2599      |\n","|    policy_loss        | -18.7     |\n","|    reward             | 1.6068777 |\n","|    std                | 1.02      |\n","|    value_loss         | 0.469     |\n","-------------------------------------\n","Episode: 14\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 143        |\n","|    iterations         | 2700       |\n","|    time_elapsed       | 94         |\n","|    total_timesteps    | 13500      |\n","| train/                |            |\n","|    entropy_loss       | -41.9      |\n","|    explained_variance | -0.454     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2699       |\n","|    policy_loss        | -26.4      |\n","|    reward             | -1.2953645 |\n","|    std                | 1.03       |\n","|    value_loss         | 1          |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 142       |\n","|    iterations         | 2800      |\n","|    time_elapsed       | 98        |\n","|    total_timesteps    | 14000     |\n","| train/                |           |\n","|    entropy_loss       | -41.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2799      |\n","|    policy_loss        | -147      |\n","|    reward             | 0.4472324 |\n","|    std                | 1.03      |\n","|    value_loss         | 14        |\n","-------------------------------------\n","Episode: 15\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 143        |\n","|    iterations         | 2900       |\n","|    time_elapsed       | 100        |\n","|    total_timesteps    | 14500      |\n","| train/                |            |\n","|    entropy_loss       | -41.8      |\n","|    explained_variance | -4.77e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2899       |\n","|    policy_loss        | 52         |\n","|    reward             | -0.5790127 |\n","|    std                | 1.02       |\n","|    value_loss         | 1.68       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 144       |\n","|    iterations         | 3000      |\n","|    time_elapsed       | 103       |\n","|    total_timesteps    | 15000     |\n","| train/                |           |\n","|    entropy_loss       | -41.9     |\n","|    explained_variance | -0.0199   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2999      |\n","|    policy_loss        | 23.4      |\n","|    reward             | 2.2493086 |\n","|    std                | 1.03      |\n","|    value_loss         | 1.9       |\n","-------------------------------------\n","Episode: 16\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 3100       |\n","|    time_elapsed       | 106        |\n","|    total_timesteps    | 15500      |\n","| train/                |            |\n","|    entropy_loss       | -41.9      |\n","|    explained_variance | 0.224      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3099       |\n","|    policy_loss        | -59.6      |\n","|    reward             | 0.20635952 |\n","|    std                | 1.03       |\n","|    value_loss         | 2.46       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 142         |\n","|    iterations         | 3200        |\n","|    time_elapsed       | 111         |\n","|    total_timesteps    | 16000       |\n","| train/                |             |\n","|    entropy_loss       | -41.9       |\n","|    explained_variance | 0.729       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3199        |\n","|    policy_loss        | 123         |\n","|    reward             | -0.20895118 |\n","|    std                | 1.03        |\n","|    value_loss         | 9.14        |\n","---------------------------------------\n","Episode: 17\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 143       |\n","|    iterations         | 3300      |\n","|    time_elapsed       | 115       |\n","|    total_timesteps    | 16500     |\n","| train/                |           |\n","|    entropy_loss       | -41.9     |\n","|    explained_variance | 0.272     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3299      |\n","|    policy_loss        | 124       |\n","|    reward             | 1.0637115 |\n","|    std                | 1.03      |\n","|    value_loss         | 10.8      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 144      |\n","|    iterations         | 3400     |\n","|    time_elapsed       | 117      |\n","|    total_timesteps    | 17000    |\n","| train/                |          |\n","|    entropy_loss       | -42      |\n","|    explained_variance | -0.3     |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 3399     |\n","|    policy_loss        | -127     |\n","|    reward             | 3.19     |\n","|    std                | 1.03     |\n","|    value_loss         | 11.8     |\n","------------------------------------\n","Episode: 18\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 144         |\n","|    iterations         | 3500        |\n","|    time_elapsed       | 120         |\n","|    total_timesteps    | 17500       |\n","| train/                |             |\n","|    entropy_loss       | -42         |\n","|    explained_variance | 0.605       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3499        |\n","|    policy_loss        | 2.85        |\n","|    reward             | -0.35632434 |\n","|    std                | 1.03        |\n","|    value_loss         | 0.982       |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 144        |\n","|    iterations         | 3600       |\n","|    time_elapsed       | 124        |\n","|    total_timesteps    | 18000      |\n","| train/                |            |\n","|    entropy_loss       | -42        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3599       |\n","|    policy_loss        | 90.1       |\n","|    reward             | -1.5739106 |\n","|    std                | 1.03       |\n","|    value_loss         | 7.83       |\n","--------------------------------------\n","Episode: 19\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 144       |\n","|    iterations         | 3700      |\n","|    time_elapsed       | 127       |\n","|    total_timesteps    | 18500     |\n","| train/                |           |\n","|    entropy_loss       | -42.1     |\n","|    explained_variance | -0.104    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3699      |\n","|    policy_loss        | -4.36     |\n","|    reward             | 2.3251421 |\n","|    std                | 1.03      |\n","|    value_loss         | 0.485     |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 3800      |\n","|    time_elapsed       | 130       |\n","|    total_timesteps    | 19000     |\n","| train/                |           |\n","|    entropy_loss       | -42.1     |\n","|    explained_variance | -0.0721   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3799      |\n","|    policy_loss        | 4.7       |\n","|    reward             | 3.3950686 |\n","|    std                | 1.03      |\n","|    value_loss         | 0.742     |\n","-------------------------------------\n","Episode: 20\n","day: 1007, episode: 20\n","begin_total_asset: 1000000.00\n","end_total_asset: 1037959.34\n","total_reward: 37959.34\n","total_cost: 21557.90\n","total_trades: 17686\n","Sharpe: 0.191\n","=================================\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 146         |\n","|    iterations         | 3900        |\n","|    time_elapsed       | 133         |\n","|    total_timesteps    | 19500       |\n","| train/                |             |\n","|    entropy_loss       | -42         |\n","|    explained_variance | 0.23        |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3899        |\n","|    policy_loss        | -19.7       |\n","|    reward             | -0.97216886 |\n","|    std                | 1.03        |\n","|    value_loss         | 2.84        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 4000      |\n","|    time_elapsed       | 136       |\n","|    total_timesteps    | 20000     |\n","| train/                |           |\n","|    entropy_loss       | -42.1     |\n","|    explained_variance | -0.0277   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3999      |\n","|    policy_loss        | 58        |\n","|    reward             | 0.3175358 |\n","|    std                | 1.03      |\n","|    value_loss         | 2.94      |\n","-------------------------------------\n"]}],"source":["trained_a2c = agent.train_model(model=model_a2c,\n","                             tb_log_name='a2c',\n","                             total_timesteps=20000) if if_using_a2c else None"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1718875540634,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"nkfSleGAyiK8"},"outputs":[],"source":["trained_a2c.save(TRAINED_MODEL_DIR + \"agent_a2c\") if if_using_a2c else None"]},{"cell_type":"markdown","metadata":{"id":"hT19ibDgyiK8"},"source":["### Agent 2: DDPG"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718875540634,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"TGz6xWx6yiK8","outputId":"3b898aca-8d31-4587-d2cb-70767c3d5e6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n","Using cuda device\n","Logging to results/ddpg\n"]}],"source":["agent = DRLAgent(env = env_train)\n","model_ddpg = agent.get_model(\"ddpg\")\n","\n","if if_using_ddpg:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + 'ddpg'\n","  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_ddpg.set_logger(new_logger_ddpg)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237433,"status":"ok","timestamp":1718875778062,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"k0ErtaspyiK9","outputId":"d0bef0cd-f7ea-45bc-ed42-79fe77fbbf1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode: 22\n","Episode: 23\n","Episode: 24\n","Episode: 25\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 4           |\n","|    fps             | 82          |\n","|    time_elapsed    | 48          |\n","|    total_timesteps | 4032        |\n","| train/             |             |\n","|    actor_loss      | 53.4        |\n","|    critic_loss     | 178         |\n","|    learning_rate   | 0.001       |\n","|    n_updates       | 3931        |\n","|    reward          | -0.04534058 |\n","------------------------------------\n","Episode: 26\n","Episode: 27\n","Episode: 28\n","Episode: 29\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 8           |\n","|    fps             | 84          |\n","|    time_elapsed    | 95          |\n","|    total_timesteps | 8064        |\n","| train/             |             |\n","|    actor_loss      | 40.8        |\n","|    critic_loss     | 0.692       |\n","|    learning_rate   | 0.001       |\n","|    n_updates       | 7963        |\n","|    reward          | -0.04534058 |\n","------------------------------------\n","Episode: 30\n","day: 1007, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 1768763.68\n","total_reward: 768763.68\n","total_cost: 998.99\n","total_trades: 18119\n","Sharpe: 0.770\n","=================================\n","Episode: 31\n","Episode: 32\n","Episode: 33\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 12          |\n","|    fps             | 84          |\n","|    time_elapsed    | 142         |\n","|    total_timesteps | 12096       |\n","| train/             |             |\n","|    actor_loss      | 34.8        |\n","|    critic_loss     | 0.31        |\n","|    learning_rate   | 0.001       |\n","|    n_updates       | 11995       |\n","|    reward          | -0.04534058 |\n","------------------------------------\n","Episode: 34\n","Episode: 35\n","Episode: 36\n","Episode: 37\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 16          |\n","|    fps             | 84          |\n","|    time_elapsed    | 191         |\n","|    total_timesteps | 16128       |\n","| train/             |             |\n","|    actor_loss      | 28.4        |\n","|    critic_loss     | 24.7        |\n","|    learning_rate   | 0.001       |\n","|    n_updates       | 16027       |\n","|    reward          | -0.04534058 |\n","------------------------------------\n","Episode: 38\n","Episode: 39\n","Episode: 40\n","day: 1007, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 1768763.68\n","total_reward: 768763.68\n","total_cost: 998.99\n","total_trades: 18119\n","Sharpe: 0.770\n","=================================\n"]}],"source":["trained_ddpg = agent.train_model(model=model_ddpg,\n","                            tb_log_name='ddpg',\n","                            total_timesteps=20000) if if_using_ddpg else None"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1718875778063,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"ddzjqxQryiK9"},"outputs":[],"source":["trained_ddpg.save(TRAINED_MODEL_DIR + \"agent_ddpg\") if if_using_ddpg else None"]},{"cell_type":"markdown","metadata":{"id":"CycTaXfYyiK9"},"source":["### Agent 3: PPO"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1718875778063,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"xXm8aN3pyiK_","outputId":"7a531aa9-3992-4155-8f75-a8143f0831fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cuda device\n","Logging to results/ppo\n"]}],"source":["agent = DRLAgent(env = env_train)\n","PPO_PARAMS = {\n","    \"n_steps\": 2048,\n","    \"ent_coef\": 0.01,\n","    \"learning_rate\": 0.00025,\n","    \"batch_size\": 128,\n","}\n","model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n","\n","if if_using_ppo:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + 'ppo'\n","  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_ppo.set_logger(new_logger_ppo)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118691,"status":"ok","timestamp":1718875896749,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"QivMPu9-yiK_","outputId":"15aad434-a50b-4141-f4c6-8250dfe109b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode: 42\n","Episode: 43\n","-----------------------------------\n","| time/              |            |\n","|    fps             | 177        |\n","|    iterations      | 1          |\n","|    time_elapsed    | 11         |\n","|    total_timesteps | 2048       |\n","| train/             |            |\n","|    reward          | 0.05710453 |\n","-----------------------------------\n","Episode: 44\n","Episode: 45\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 169         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 24          |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.017482497 |\n","|    clip_fraction        | 0.213       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.0424     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.26        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.04       |\n","|    reward               | 1.0971578   |\n","|    std                  | 1           |\n","|    value_loss           | 10.3        |\n","-----------------------------------------\n","Episode: 46\n","Episode: 47\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 173         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 35          |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.016854934 |\n","|    clip_fraction        | 0.194       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | 0.00151     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.61        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0355     |\n","|    reward               | 0.9606207   |\n","|    std                  | 1           |\n","|    value_loss           | 10.4        |\n","-----------------------------------------\n","Episode: 48\n","Episode: 49\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 175         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 46          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.017332658 |\n","|    clip_fraction        | 0.191       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | 0.0193      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.43        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0366     |\n","|    reward               | 0.36804605  |\n","|    std                  | 1.01        |\n","|    value_loss           | 10.3        |\n","-----------------------------------------\n","Episode: 50\n","day: 1007, episode: 50\n","begin_total_asset: 1000000.00\n","end_total_asset: 1507635.65\n","total_reward: 507635.65\n","total_cost: 185575.66\n","total_trades: 26845\n","Sharpe: 0.576\n","=================================\n","Episode: 51\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 172         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 59          |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.015327422 |\n","|    clip_fraction        | 0.174       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | 0.0262      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.39        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0362     |\n","|    reward               | 0.12145667  |\n","|    std                  | 1.01        |\n","|    value_loss           | 10.8        |\n","-----------------------------------------\n","Episode: 52\n","Episode: 53\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 171         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 71          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.015304516 |\n","|    clip_fraction        | 0.176       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | 0.0517      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.49        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.0308     |\n","|    reward               | -0.38146242 |\n","|    std                  | 1.01        |\n","|    value_loss           | 10.9        |\n","-----------------------------------------\n","Episode: 54\n","Episode: 55\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 171        |\n","|    iterations           | 7          |\n","|    time_elapsed         | 83         |\n","|    total_timesteps      | 14336      |\n","| train/                  |            |\n","|    approx_kl            | 0.01873799 |\n","|    clip_fraction        | 0.201      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.5      |\n","|    explained_variance   | 0.0386     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 3.18       |\n","|    n_updates            | 60         |\n","|    policy_gradient_loss | -0.0375    |\n","|    reward               | -1.4917442 |\n","|    std                  | 1.01       |\n","|    value_loss           | 9.34       |\n","----------------------------------------\n","Episode: 56\n","Episode: 57\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 171         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 95          |\n","|    total_timesteps      | 16384       |\n","| train/                  |             |\n","|    approx_kl            | 0.015321726 |\n","|    clip_fraction        | 0.16        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | 0.0522      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.64        |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.0348     |\n","|    reward               | 0.25086516  |\n","|    std                  | 1.01        |\n","|    value_loss           | 10.1        |\n","-----------------------------------------\n","Episode: 58\n","Episode: 59\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 173        |\n","|    iterations           | 9          |\n","|    time_elapsed         | 106        |\n","|    total_timesteps      | 18432      |\n","| train/                  |            |\n","|    approx_kl            | 0.01780029 |\n","|    clip_fraction        | 0.21       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.6      |\n","|    explained_variance   | 0.0801     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 2.85       |\n","|    n_updates            | 80         |\n","|    policy_gradient_loss | -0.0372    |\n","|    reward               | 0.113283   |\n","|    std                  | 1.02       |\n","|    value_loss           | 9.53       |\n","----------------------------------------\n","Episode: 60\n","day: 1007, episode: 60\n","begin_total_asset: 1000000.00\n","end_total_asset: 1494985.97\n","total_reward: 494985.97\n","total_cost: 184335.44\n","total_trades: 26542\n","Sharpe: 0.570\n","=================================\n","Episode: 61\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 173         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 117         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.017344818 |\n","|    clip_fraction        | 0.183       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | 0.0789      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.17        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0353     |\n","|    reward               | -0.13923648 |\n","|    std                  | 1.02        |\n","|    value_loss           | 11.9        |\n","-----------------------------------------\n"]}],"source":["trained_ppo = agent.train_model(model=model_ppo,\n","                             tb_log_name='ppo',\n","                             total_timesteps=20000) if if_using_ppo else None"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1718875896750,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"LWZtNGL9yiLA"},"outputs":[],"source":["trained_ppo.save(TRAINED_MODEL_DIR + \"agent_ppo\") if if_using_ppo else None"]},{"cell_type":"markdown","metadata":{"id":"G7pOR9jLiuwM"},"source":["## Ensemble Strategy"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1718875896750,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"id6SKw6MjGrL"},"outputs":[],"source":["ensemble_data = processed_data"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1718875896750,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"wxrKUA6nyiLA"},"outputs":[],"source":["rebalance_window = 63\n","validation_window = 63\n","\n","env_ensemble_kwargs = {\n","    \"hmax\": 100,\n","    \"initial_amount\": 1000000,\n","    \"buy_cost_pct\": 0.001,\n","    \"sell_cost_pct\": 0.001,\n","    \"state_space\": state_space,\n","    \"stock_dim\": stock_dimension,\n","    \"tech_indicator_list\": INDICATORS,\n","    \"action_space\": stock_dimension,\n","    \"reward_scaling\": 1e-4,\n","    \"print_verbosity\":5\n","}\n","\n","ensemble_agent = DRLEnsembleAgent(df=ensemble_data,\n","                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n","                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n","                 rebalance_window=rebalance_window,\n","                 validation_window=validation_window,\n","                 **env_ensemble_kwargs) if if_using_ensemble else None"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1718875896750,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"XyEMMXnjyiLA"},"outputs":[],"source":["A2C_model_kwargs = {\n","                    'n_steps': 5,\n","                    'ent_coef': 0.005,\n","                    'learning_rate': 0.0007\n","                    }\n","\n","PPO_model_kwargs = {\n","                    \"ent_coef\":0.01,\n","                    \"n_steps\": 2048,\n","                    \"learning_rate\": 0.00025,\n","                    \"batch_size\": 128\n","                    }\n","\n","DDPG_model_kwargs = {\n","                      #\"action_noise\":\"ornstein_uhlenbeck\",\n","                      \"buffer_size\": 10_000,\n","                      \"learning_rate\": 0.0005,\n","                      \"batch_size\": 64\n","                    }\n","\n","timesteps_dict = {'a2c' : 20000,\n","                 'ppo' : 20000,\n","                 'ddpg' : 20000,\n","                 }"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3065100,"status":"ok","timestamp":1718878961829,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"WduHxQWjyiLA","outputId":"c4a2f2d4-9600-4ad0-d675-200b457e1046"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mK蘯ｿt qu蘯｣ truy盻］ tr盻ｱc tuy蘯ｿn b盻 c蘯ｯt b盻孚 ﾄ黛ｺｿn 5000 dﾃｲng cu盻訴.\u001b[0m\n","|    explained_variance | -0.0144   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 999       |\n","|    policy_loss        | -254      |\n","|    reward             | 2.6416326 |\n","|    std                | 0.994     |\n","|    value_loss         | 42.6      |\n","-------------------------------------\n","Episode: 5\n","day: 1070, episode: 5\n","begin_total_asset: 1000000.00\n","end_total_asset: 1568851.39\n","total_reward: 568851.39\n","total_cost: 61100.22\n","total_trades: 21003\n","Sharpe: 0.618\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 150        |\n","|    iterations         | 1100       |\n","|    time_elapsed       | 36         |\n","|    total_timesteps    | 5500       |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | 0.0575     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1099       |\n","|    policy_loss        | -27.9      |\n","|    reward             | 0.10829289 |\n","|    std                | 0.995      |\n","|    value_loss         | 0.733      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 151        |\n","|    iterations         | 1200       |\n","|    time_elapsed       | 39         |\n","|    total_timesteps    | 6000       |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | 0.337      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1199       |\n","|    policy_loss        | 10.3       |\n","|    reward             | 0.66493475 |\n","|    std                | 0.994      |\n","|    value_loss         | 1.08       |\n","--------------------------------------\n","Episode: 6\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 153         |\n","|    iterations         | 1300        |\n","|    time_elapsed       | 42          |\n","|    total_timesteps    | 6500        |\n","| train/                |             |\n","|    entropy_loss       | -41         |\n","|    explained_variance | 0.235       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1299        |\n","|    policy_loss        | 19.9        |\n","|    reward             | 0.120887525 |\n","|    std                | 0.994       |\n","|    value_loss         | 0.783       |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 152        |\n","|    iterations         | 1400       |\n","|    time_elapsed       | 45         |\n","|    total_timesteps    | 7000       |\n","| train/                |            |\n","|    entropy_loss       | -40.9      |\n","|    explained_variance | -0.00608   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1399       |\n","|    policy_loss        | 111        |\n","|    reward             | -2.4698062 |\n","|    std                | 0.991      |\n","|    value_loss         | 12.9       |\n","--------------------------------------\n","Episode: 7\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 150         |\n","|    iterations         | 1500        |\n","|    time_elapsed       | 49          |\n","|    total_timesteps    | 7500        |\n","| train/                |             |\n","|    entropy_loss       | -40.9       |\n","|    explained_variance | 0.065       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1499        |\n","|    policy_loss        | 20.1        |\n","|    reward             | 0.104692005 |\n","|    std                | 0.99        |\n","|    value_loss         | 1.28        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 152       |\n","|    iterations         | 1600      |\n","|    time_elapsed       | 52        |\n","|    total_timesteps    | 8000      |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0.63      |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1599      |\n","|    policy_loss        | -5.47     |\n","|    reward             | 0.7482459 |\n","|    std                | 0.994     |\n","|    value_loss         | 0.13      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 153        |\n","|    iterations         | 1700       |\n","|    time_elapsed       | 55         |\n","|    total_timesteps    | 8500       |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | -0.133     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1699       |\n","|    policy_loss        | 57.4       |\n","|    reward             | 0.51150614 |\n","|    std                | 0.995      |\n","|    value_loss         | 6.01       |\n","--------------------------------------\n","Episode: 8\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 153       |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 58        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0.0327    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | -48.6     |\n","|    reward             | 0.2784104 |\n","|    std                | 0.994     |\n","|    value_loss         | 4.2       |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 151       |\n","|    iterations         | 1900      |\n","|    time_elapsed       | 62        |\n","|    total_timesteps    | 9500      |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0.106     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1899      |\n","|    policy_loss        | -84.6     |\n","|    reward             | 1.4045419 |\n","|    std                | 0.993     |\n","|    value_loss         | 5.63      |\n","-------------------------------------\n","Episode: 9\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 152        |\n","|    iterations         | 2000       |\n","|    time_elapsed       | 65         |\n","|    total_timesteps    | 10000      |\n","| train/                |            |\n","|    entropy_loss       | -40.9      |\n","|    explained_variance | 0.203      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1999       |\n","|    policy_loss        | 42.9       |\n","|    reward             | 0.43468755 |\n","|    std                | 0.993      |\n","|    value_loss         | 2.03       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 153        |\n","|    iterations         | 2100       |\n","|    time_elapsed       | 68         |\n","|    total_timesteps    | 10500      |\n","| train/                |            |\n","|    entropy_loss       | -40.9      |\n","|    explained_variance | -0.0789    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2099       |\n","|    policy_loss        | -61.5      |\n","|    reward             | 0.38060072 |\n","|    std                | 0.992      |\n","|    value_loss         | 3.99       |\n","--------------------------------------\n","Episode: 10\n","day: 1070, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 1534897.87\n","total_reward: 534897.87\n","total_cost: 24173.26\n","total_trades: 19151\n","Sharpe: 0.582\n","=================================\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 154         |\n","|    iterations         | 2200        |\n","|    time_elapsed       | 71          |\n","|    total_timesteps    | 11000       |\n","| train/                |             |\n","|    entropy_loss       | -40.9       |\n","|    explained_variance | -0.0333     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2199        |\n","|    policy_loss        | 9.17        |\n","|    reward             | -0.44273388 |\n","|    std                | 0.993       |\n","|    value_loss         | 0.55        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 152       |\n","|    iterations         | 2300      |\n","|    time_elapsed       | 75        |\n","|    total_timesteps    | 11500     |\n","| train/                |           |\n","|    entropy_loss       | -40.9     |\n","|    explained_variance | 0.0343    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2299      |\n","|    policy_loss        | 15.2      |\n","|    reward             | 0.7292252 |\n","|    std                | 0.993     |\n","|    value_loss         | 0.185     |\n","-------------------------------------\n","Episode: 11\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 152         |\n","|    iterations         | 2400        |\n","|    time_elapsed       | 78          |\n","|    total_timesteps    | 12000       |\n","| train/                |             |\n","|    entropy_loss       | -40.9       |\n","|    explained_variance | -1.19e-07   |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2399        |\n","|    policy_loss        | 40.9        |\n","|    reward             | -0.13958853 |\n","|    std                | 0.993       |\n","|    value_loss         | 1.26        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 153       |\n","|    iterations         | 2500      |\n","|    time_elapsed       | 81        |\n","|    total_timesteps    | 12500     |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0.0248    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2499      |\n","|    policy_loss        | -3.6      |\n","|    reward             | 3.4631324 |\n","|    std                | 0.995     |\n","|    value_loss         | 5.03      |\n","-------------------------------------\n","Episode: 12\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 154        |\n","|    iterations         | 2600       |\n","|    time_elapsed       | 84         |\n","|    total_timesteps    | 13000      |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | 0.176      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2599       |\n","|    policy_loss        | 48.8       |\n","|    reward             | 0.73981917 |\n","|    std                | 0.995      |\n","|    value_loss         | 2.27       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 153        |\n","|    iterations         | 2700       |\n","|    time_elapsed       | 87         |\n","|    total_timesteps    | 13500      |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | -0.109     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2699       |\n","|    policy_loss        | -77.1      |\n","|    reward             | -1.5402486 |\n","|    std                | 0.998      |\n","|    value_loss         | 3.72       |\n","--------------------------------------\n","Episode: 13\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 153        |\n","|    iterations         | 2800       |\n","|    time_elapsed       | 91         |\n","|    total_timesteps    | 14000      |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2799       |\n","|    policy_loss        | 47.8       |\n","|    reward             | -2.8062603 |\n","|    std                | 0.997      |\n","|    value_loss         | 1.54       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 153         |\n","|    iterations         | 2900        |\n","|    time_elapsed       | 94          |\n","|    total_timesteps    | 14500       |\n","| train/                |             |\n","|    entropy_loss       | -41         |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2899        |\n","|    policy_loss        | 19.8        |\n","|    reward             | -0.64121634 |\n","|    std                | 0.997       |\n","|    value_loss         | 9.1         |\n","---------------------------------------\n","Episode: 14\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 154          |\n","|    iterations         | 3000         |\n","|    time_elapsed       | 97           |\n","|    total_timesteps    | 15000        |\n","| train/                |              |\n","|    entropy_loss       | -41          |\n","|    explained_variance | 0.138        |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 2999         |\n","|    policy_loss        | -263         |\n","|    reward             | -0.053902153 |\n","|    std                | 0.996        |\n","|    value_loss         | 52.4         |\n","----------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 154        |\n","|    iterations         | 3100       |\n","|    time_elapsed       | 100        |\n","|    total_timesteps    | 15500      |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | -0.153     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3099       |\n","|    policy_loss        | -42.2      |\n","|    reward             | -1.2566832 |\n","|    std                | 0.998      |\n","|    value_loss         | 1.12       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 153         |\n","|    iterations         | 3200        |\n","|    time_elapsed       | 104         |\n","|    total_timesteps    | 16000       |\n","| train/                |             |\n","|    entropy_loss       | -41.1       |\n","|    explained_variance | 0.0546      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3199        |\n","|    policy_loss        | 3.92        |\n","|    reward             | -0.37645814 |\n","|    std                | 1           |\n","|    value_loss         | 1.08        |\n","---------------------------------------\n","Episode: 15\n","day: 1070, episode: 15\n","begin_total_asset: 1000000.00\n","end_total_asset: 1522639.85\n","total_reward: 522639.85\n","total_cost: 8234.64\n","total_trades: 18275\n","Sharpe: 0.565\n","=================================\n","-----------------------------------------\n","| time/                 |               |\n","|    fps                | 153           |\n","|    iterations         | 3300          |\n","|    time_elapsed       | 107           |\n","|    total_timesteps    | 16500         |\n","| train/                |               |\n","|    entropy_loss       | -41.2         |\n","|    explained_variance | -0.0255       |\n","|    learning_rate      | 0.0007        |\n","|    n_updates          | 3299          |\n","|    policy_loss        | -11.6         |\n","|    reward             | 0.00021695122 |\n","|    std                | 1             |\n","|    value_loss         | 0.163         |\n","-----------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 154        |\n","|    iterations         | 3400       |\n","|    time_elapsed       | 110        |\n","|    total_timesteps    | 17000      |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0.00555    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3399       |\n","|    policy_loss        | -88.8      |\n","|    reward             | -2.8085773 |\n","|    std                | 1.01       |\n","|    value_loss         | 8.51       |\n","--------------------------------------\n","Episode: 16\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 154         |\n","|    iterations         | 3500        |\n","|    time_elapsed       | 112         |\n","|    total_timesteps    | 17500       |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | -0.00916    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3499        |\n","|    policy_loss        | 114         |\n","|    reward             | 0.110727035 |\n","|    std                | 1.01        |\n","|    value_loss         | 10          |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 154       |\n","|    iterations         | 3600      |\n","|    time_elapsed       | 116       |\n","|    total_timesteps    | 18000     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3599      |\n","|    policy_loss        | -38.4     |\n","|    reward             | 1.1264782 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.47      |\n","-------------------------------------\n","Episode: 17\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 154         |\n","|    iterations         | 3700        |\n","|    time_elapsed       | 119         |\n","|    total_timesteps    | 18500       |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | 0.589       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3699        |\n","|    policy_loss        | 27.8        |\n","|    reward             | -0.15747283 |\n","|    std                | 1.01        |\n","|    value_loss         | 0.542       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 154       |\n","|    iterations         | 3800      |\n","|    time_elapsed       | 122       |\n","|    total_timesteps    | 19000     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 0.0353    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3799      |\n","|    policy_loss        | -54.3     |\n","|    reward             | -2.363226 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.54      |\n","-------------------------------------\n","Episode: 18\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 155        |\n","|    iterations         | 3900       |\n","|    time_elapsed       | 125        |\n","|    total_timesteps    | 19500      |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0.162      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3899       |\n","|    policy_loss        | 19.8       |\n","|    reward             | 0.32188365 |\n","|    std                | 1.01       |\n","|    value_loss         | 3.05       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 155        |\n","|    iterations         | 4000       |\n","|    time_elapsed       | 128        |\n","|    total_timesteps    | 20000      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -0.022     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3999       |\n","|    policy_loss        | 173        |\n","|    reward             | -0.9015049 |\n","|    std                | 1.01       |\n","|    value_loss         | 18.6       |\n","--------------------------------------\n","======a2c Validation from:  2022-04-04 to  2022-07-06\n","Episode: 1\n","a2c Sharpe Ratio:  -0.16043681519416056\n","======ddpg Training========\n","{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n","Using cuda device\n","Logging to tensorboard_log//ddpg/ddpg_189_1\n","Episode: 20\n","day: 1070, episode: 20\n","begin_total_asset: 1000000.00\n","end_total_asset: 1760665.45\n","total_reward: 760665.45\n","total_cost: 14867.78\n","total_trades: 16503\n","Sharpe: 0.732\n","=================================\n","Episode: 21\n","Episode: 22\n","Episode: 23\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 4         |\n","|    fps             | 85        |\n","|    time_elapsed    | 49        |\n","|    total_timesteps | 4284      |\n","| train/             |           |\n","|    actor_loss      | -52.3     |\n","|    critic_loss     | 8.58e+03  |\n","|    learning_rate   | 0.0005    |\n","|    n_updates       | 4183      |\n","|    reward          | 0.8271213 |\n","----------------------------------\n","Episode: 24\n","Episode: 25\n","day: 1070, episode: 25\n","begin_total_asset: 1000000.00\n","end_total_asset: 1757551.29\n","total_reward: 757551.29\n","total_cost: 1345.91\n","total_trades: 9652\n","Sharpe: 0.725\n","=================================\n","Episode: 26\n","Episode: 27\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 8         |\n","|    fps             | 85        |\n","|    time_elapsed    | 100       |\n","|    total_timesteps | 8568      |\n","| train/             |           |\n","|    actor_loss      | -29.9     |\n","|    critic_loss     | 17.1      |\n","|    learning_rate   | 0.0005    |\n","|    n_updates       | 8467      |\n","|    reward          | 0.8271213 |\n","----------------------------------\n","Episode: 28\n","Episode: 29\n","Episode: 30\n","day: 1070, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 1757551.29\n","total_reward: 757551.29\n","total_cost: 1345.91\n","total_trades: 9652\n","Sharpe: 0.725\n","=================================\n","Episode: 31\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 12        |\n","|    fps             | 85        |\n","|    time_elapsed    | 151       |\n","|    total_timesteps | 12852     |\n","| train/             |           |\n","|    actor_loss      | -26.1     |\n","|    critic_loss     | 10.2      |\n","|    learning_rate   | 0.0005    |\n","|    n_updates       | 12751     |\n","|    reward          | 0.8271213 |\n","----------------------------------\n","Episode: 32\n","Episode: 33\n","Episode: 34\n","Episode: 35\n","day: 1070, episode: 35\n","begin_total_asset: 1000000.00\n","end_total_asset: 1757551.29\n","total_reward: 757551.29\n","total_cost: 1345.91\n","total_trades: 9652\n","Sharpe: 0.725\n","=================================\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 16        |\n","|    fps             | 84        |\n","|    time_elapsed    | 203       |\n","|    total_timesteps | 17136     |\n","| train/             |           |\n","|    actor_loss      | -21.7     |\n","|    critic_loss     | 0.679     |\n","|    learning_rate   | 0.0005    |\n","|    n_updates       | 17035     |\n","|    reward          | 0.8271213 |\n","----------------------------------\n","Episode: 36\n","Episode: 37\n","======ddpg Validation from:  2022-04-04 to  2022-07-06\n","Episode: 1\n","ddpg Sharpe Ratio:  -0.2529197168642002\n","======ppo Training========\n","{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cuda device\n","Logging to tensorboard_log//ppo/ppo_189_1\n","Episode: 39\n","-----------------------------------\n","| time/              |            |\n","|    fps             | 170        |\n","|    iterations      | 1          |\n","|    time_elapsed    | 12         |\n","|    total_timesteps | 2048       |\n","| train/             |            |\n","|    reward          | -0.7639924 |\n","-----------------------------------\n","Episode: 40\n","day: 1070, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 1280492.76\n","total_reward: 280492.76\n","total_cost: 202196.14\n","total_trades: 28694\n","Sharpe: 0.387\n","=================================\n","Episode: 41\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 166         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 24          |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.017783407 |\n","|    clip_fraction        | 0.203       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.0332     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.33        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0371     |\n","|    reward               | 0.51207143  |\n","|    std                  | 1           |\n","|    value_loss           | 10          |\n","-----------------------------------------\n","Episode: 42\n","Episode: 43\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 167         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 36          |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.014335587 |\n","|    clip_fraction        | 0.147       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.0351     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.87        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0344     |\n","|    reward               | 0.12926608  |\n","|    std                  | 1           |\n","|    value_loss           | 11.3        |\n","-----------------------------------------\n","Episode: 44\n","Episode: 45\n","day: 1070, episode: 45\n","begin_total_asset: 1000000.00\n","end_total_asset: 1527759.72\n","total_reward: 527759.72\n","total_cost: 199287.96\n","total_trades: 28461\n","Sharpe: 0.579\n","=================================\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 169        |\n","|    iterations           | 4          |\n","|    time_elapsed         | 48         |\n","|    total_timesteps      | 8192       |\n","| train/                  |            |\n","|    approx_kl            | 0.02041512 |\n","|    clip_fraction        | 0.226      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.3      |\n","|    explained_variance   | 0.0153     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 4.05       |\n","|    n_updates            | 30         |\n","|    policy_gradient_loss | -0.0452    |\n","|    reward               | -1.6207728 |\n","|    std                  | 1          |\n","|    value_loss           | 10.6       |\n","----------------------------------------\n","Episode: 46\n","Episode: 47\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 169           |\n","|    iterations           | 5             |\n","|    time_elapsed         | 60            |\n","|    total_timesteps      | 10240         |\n","| train/                  |               |\n","|    approx_kl            | 0.02066435    |\n","|    clip_fraction        | 0.217         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -41.3         |\n","|    explained_variance   | 0.00283       |\n","|    learning_rate        | 0.00025       |\n","|    loss                 | 4.52          |\n","|    n_updates            | 40            |\n","|    policy_gradient_loss | -0.0379       |\n","|    reward               | -0.0012031795 |\n","|    std                  | 1.01          |\n","|    value_loss           | 10            |\n","-------------------------------------------\n","Episode: 48\n","Episode: 49\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 167        |\n","|    iterations           | 6          |\n","|    time_elapsed         | 73         |\n","|    total_timesteps      | 12288      |\n","| train/                  |            |\n","|    approx_kl            | 0.01768959 |\n","|    clip_fraction        | 0.22       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.4      |\n","|    explained_variance   | 0.000557   |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 3.93       |\n","|    n_updates            | 50         |\n","|    policy_gradient_loss | -0.0435    |\n","|    reward               | 0.7312562  |\n","|    std                  | 1.01       |\n","|    value_loss           | 9.45       |\n","----------------------------------------\n","Episode: 50\n","day: 1070, episode: 50\n","begin_total_asset: 1000000.00\n","end_total_asset: 1393791.41\n","total_reward: 393791.41\n","total_cost: 183377.98\n","total_trades: 27741\n","Sharpe: 0.458\n","=================================\n","Episode: 51\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 166         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 85          |\n","|    total_timesteps      | 14336       |\n","| train/                  |             |\n","|    approx_kl            | 0.022549264 |\n","|    clip_fraction        | 0.23        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | 0.0466      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.09        |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0382     |\n","|    reward               | -2.8100443  |\n","|    std                  | 1.01        |\n","|    value_loss           | 7.41        |\n","-----------------------------------------\n","Episode: 52\n","Episode: 53\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 166         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 98          |\n","|    total_timesteps      | 16384       |\n","| train/                  |             |\n","|    approx_kl            | 0.021540737 |\n","|    clip_fraction        | 0.225       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | 0.0466      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.75        |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.0345     |\n","|    reward               | 0.23688017  |\n","|    std                  | 1.01        |\n","|    value_loss           | 10.9        |\n","-----------------------------------------\n","Episode: 54\n","Episode: 55\n","day: 1070, episode: 55\n","begin_total_asset: 1000000.00\n","end_total_asset: 1291059.32\n","total_reward: 291059.32\n","total_cost: 177835.99\n","total_trades: 27374\n","Sharpe: 0.373\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 166         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 111         |\n","|    total_timesteps      | 18432       |\n","| train/                  |             |\n","|    approx_kl            | 0.020662023 |\n","|    clip_fraction        | 0.214       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | 0.0106      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.98        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.0353     |\n","|    reward               | -0.15842547 |\n","|    std                  | 1.02        |\n","|    value_loss           | 11.3        |\n","-----------------------------------------\n","Episode: 56\n","Episode: 57\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 166         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 123         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.017571695 |\n","|    clip_fraction        | 0.179       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | 0.0566      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.41        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0299     |\n","|    reward               | -0.8334286  |\n","|    std                  | 1.02        |\n","|    value_loss           | 13.2        |\n","-----------------------------------------\n","======ppo Validation from:  2022-04-04 to  2022-07-06\n","Episode: 1\n","ppo Sharpe Ratio:  -0.25906576321644814\n","======Best Model Retraining from:  2018-01-01 to  2022-07-06\n","======Trading from:  2022-07-06 to  2022-10-04\n","Used Model:  <stable_baselines3.a2c.a2c.A2C object at 0x7b6b110794e0>\n","Episode: 1\n","============================================\n","turbulence_threshold:  354.94325460158456\n","======Model training from:  2018-01-01 to  2022-07-06\n","==============Model Training===========\n","======a2c Training========\n","{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n","Using cuda device\n","Logging to tensorboard_log//a2c/a2c_252_1\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 164        |\n","|    iterations         | 100        |\n","|    time_elapsed       | 3          |\n","|    total_timesteps    | 500        |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | 0.000604   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 99         |\n","|    policy_loss        | -5.79      |\n","|    reward             | 0.09357279 |\n","|    std                | 0.996      |\n","|    value_loss         | 0.058      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 162       |\n","|    iterations         | 200       |\n","|    time_elapsed       | 6         |\n","|    total_timesteps    | 1000      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0.166     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 199       |\n","|    policy_loss        | 19.1      |\n","|    reward             | 1.6058716 |\n","|    std                | 0.996     |\n","|    value_loss         | 0.355     |\n","-------------------------------------\n","Episode: 1\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 157        |\n","|    iterations         | 300        |\n","|    time_elapsed       | 9          |\n","|    total_timesteps    | 1500       |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | -0.0704    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 299        |\n","|    policy_loss        | 63.4       |\n","|    reward             | 0.60097605 |\n","|    std                | 0.996      |\n","|    value_loss         | 3.18       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 144        |\n","|    iterations         | 400        |\n","|    time_elapsed       | 13         |\n","|    total_timesteps    | 2000       |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | 0.000131   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 399        |\n","|    policy_loss        | 39.9       |\n","|    reward             | 0.18221697 |\n","|    std                | 0.997      |\n","|    value_loss         | 1.11       |\n","--------------------------------------\n","Episode: 2\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 147      |\n","|    iterations         | 500      |\n","|    time_elapsed       | 16       |\n","|    total_timesteps    | 2500     |\n","| train/                |          |\n","|    entropy_loss       | -41      |\n","|    explained_variance | -0.188   |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 499      |\n","|    policy_loss        | -28.3    |\n","|    reward             | 1.202381 |\n","|    std                | 0.997    |\n","|    value_loss         | 3.27     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 600       |\n","|    time_elapsed       | 20        |\n","|    total_timesteps    | 3000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0.00859   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 599       |\n","|    policy_loss        | -84.5     |\n","|    reward             | 0.4233187 |\n","|    std                | 0.998     |\n","|    value_loss         | 7.84      |\n","-------------------------------------\n","Episode: 3\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 151        |\n","|    iterations         | 700        |\n","|    time_elapsed       | 23         |\n","|    total_timesteps    | 3500       |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | -0.787     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 699        |\n","|    policy_loss        | -4.66      |\n","|    reward             | 0.17174001 |\n","|    std                | 1          |\n","|    value_loss         | 0.278      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 800        |\n","|    time_elapsed       | 27         |\n","|    total_timesteps    | 4000       |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 799        |\n","|    policy_loss        | -56.7      |\n","|    reward             | -1.7918451 |\n","|    std                | 1          |\n","|    value_loss         | 2.86       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 148       |\n","|    iterations         | 900       |\n","|    time_elapsed       | 30        |\n","|    total_timesteps    | 4500      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0.107     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 899       |\n","|    policy_loss        | 115       |\n","|    reward             | 0.8471981 |\n","|    std                | 1         |\n","|    value_loss         | 13.1      |\n","-------------------------------------\n","Episode: 4\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 149        |\n","|    iterations         | 1000       |\n","|    time_elapsed       | 33         |\n","|    total_timesteps    | 5000       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0.0722     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 999        |\n","|    policy_loss        | 47.7       |\n","|    reward             | 0.26149514 |\n","|    std                | 1          |\n","|    value_loss         | 1.9        |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 151       |\n","|    iterations         | 1100      |\n","|    time_elapsed       | 36        |\n","|    total_timesteps    | 5500      |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | 0.78      |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1099      |\n","|    policy_loss        | 72.1      |\n","|    reward             | 1.0961013 |\n","|    std                | 1         |\n","|    value_loss         | 2.86      |\n","-------------------------------------\n","Episode: 5\n","day: 1133, episode: 5\n","begin_total_asset: 1000000.00\n","end_total_asset: 1162982.28\n","total_reward: 162982.28\n","total_cost: 97128.73\n","total_trades: 22899\n","Sharpe: 0.260\n","=================================\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 147          |\n","|    iterations         | 1200         |\n","|    time_elapsed       | 40           |\n","|    total_timesteps    | 6000         |\n","| train/                |              |\n","|    entropy_loss       | -41.3        |\n","|    explained_variance | 5.96e-08     |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 1199         |\n","|    policy_loss        | -31.8        |\n","|    reward             | -0.024328103 |\n","|    std                | 1            |\n","|    value_loss         | 1.31         |\n","----------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 148       |\n","|    iterations         | 1300      |\n","|    time_elapsed       | 43        |\n","|    total_timesteps    | 6500      |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | 0.225     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1299      |\n","|    policy_loss        | -5.95     |\n","|    reward             | 1.4813836 |\n","|    std                | 1         |\n","|    value_loss         | 0.236     |\n","-------------------------------------\n","Episode: 6\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 149        |\n","|    iterations         | 1400       |\n","|    time_elapsed       | 46         |\n","|    total_timesteps    | 7000       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | -0.43      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1399       |\n","|    policy_loss        | 35         |\n","|    reward             | -2.4572473 |\n","|    std                | 1          |\n","|    value_loss         | 1.47       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 150       |\n","|    iterations         | 1500      |\n","|    time_elapsed       | 49        |\n","|    total_timesteps    | 7500      |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | -0.399    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1499      |\n","|    policy_loss        | 59.3      |\n","|    reward             | 1.5811068 |\n","|    std                | 1         |\n","|    value_loss         | 3.3       |\n","-------------------------------------\n","Episode: 7\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 1600      |\n","|    time_elapsed       | 53        |\n","|    total_timesteps    | 8000      |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | 0.021     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1599      |\n","|    policy_loss        | -7.1      |\n","|    reward             | 1.2285869 |\n","|    std                | 1         |\n","|    value_loss         | 3.16      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 148        |\n","|    iterations         | 1700       |\n","|    time_elapsed       | 57         |\n","|    total_timesteps    | 8500       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0.00763    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1699       |\n","|    policy_loss        | -193       |\n","|    reward             | -3.1613586 |\n","|    std                | 1          |\n","|    value_loss         | 54.9       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 60        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | -0.132    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | -201      |\n","|    reward             | 0.5918296 |\n","|    std                | 1         |\n","|    value_loss         | 25.2      |\n","-------------------------------------\n","Episode: 8\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 150         |\n","|    iterations         | 1900        |\n","|    time_elapsed       | 63          |\n","|    total_timesteps    | 9500        |\n","| train/                |             |\n","|    entropy_loss       | -41.2       |\n","|    explained_variance | 0.0293      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1899        |\n","|    policy_loss        | 131         |\n","|    reward             | -0.06574667 |\n","|    std                | 1           |\n","|    value_loss         | 13.4        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 150         |\n","|    iterations         | 2000        |\n","|    time_elapsed       | 66          |\n","|    total_timesteps    | 10000       |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | -0.0471     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1999        |\n","|    policy_loss        | -61.2       |\n","|    reward             | -0.18932666 |\n","|    std                | 1           |\n","|    value_loss         | 2.78        |\n","---------------------------------------\n","Episode: 9\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 148         |\n","|    iterations         | 2100        |\n","|    time_elapsed       | 70          |\n","|    total_timesteps    | 10500       |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2099        |\n","|    policy_loss        | 22.7        |\n","|    reward             | -0.18711631 |\n","|    std                | 1.01        |\n","|    value_loss         | 0.405       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 2200      |\n","|    time_elapsed       | 73        |\n","|    total_timesteps    | 11000     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 0.14      |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2199      |\n","|    policy_loss        | 63.2      |\n","|    reward             | 1.9505044 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.71      |\n","-------------------------------------\n","Episode: 10\n","day: 1133, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 1212830.68\n","total_reward: 212830.68\n","total_cost: 47058.91\n","total_trades: 20476\n","Sharpe: 0.295\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 150        |\n","|    iterations         | 2300       |\n","|    time_elapsed       | 76         |\n","|    total_timesteps    | 11500      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2299       |\n","|    policy_loss        | -19.6      |\n","|    reward             | 0.38397032 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.54       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 150        |\n","|    iterations         | 2400       |\n","|    time_elapsed       | 79         |\n","|    total_timesteps    | 12000      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 0.0396     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2399       |\n","|    policy_loss        | 149        |\n","|    reward             | -0.6630136 |\n","|    std                | 1.01       |\n","|    value_loss         | 12.6       |\n","--------------------------------------\n","Episode: 11\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 148        |\n","|    iterations         | 2500       |\n","|    time_elapsed       | 84         |\n","|    total_timesteps    | 12500      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -0.0952    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2499       |\n","|    policy_loss        | -36.1      |\n","|    reward             | -4.3573103 |\n","|    std                | 1.01       |\n","|    value_loss         | 1.71       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 2600      |\n","|    time_elapsed       | 87        |\n","|    total_timesteps    | 13000     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0.0188    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2599      |\n","|    policy_loss        | -39.1     |\n","|    reward             | 2.2852337 |\n","|    std                | 1.01      |\n","|    value_loss         | 1.7       |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 2700      |\n","|    time_elapsed       | 90        |\n","|    total_timesteps    | 13500     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0.147     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2699      |\n","|    policy_loss        | -174      |\n","|    reward             | 0.8954438 |\n","|    std                | 1.01      |\n","|    value_loss         | 19.6      |\n","-------------------------------------\n","Episode: 12\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 150        |\n","|    iterations         | 2800       |\n","|    time_elapsed       | 93         |\n","|    total_timesteps    | 14000      |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | -0.366     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2799       |\n","|    policy_loss        | -23.9      |\n","|    reward             | -0.7339809 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.757      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 148       |\n","|    iterations         | 2900      |\n","|    time_elapsed       | 97        |\n","|    total_timesteps    | 14500     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0.0185    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2899      |\n","|    policy_loss        | 35.7      |\n","|    reward             | 2.0173345 |\n","|    std                | 1.01      |\n","|    value_loss         | 1.85      |\n","-------------------------------------\n","Episode: 13\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 148         |\n","|    iterations         | 3000        |\n","|    time_elapsed       | 100         |\n","|    total_timesteps    | 15000       |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | -0.144      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2999        |\n","|    policy_loss        | 23.9        |\n","|    reward             | -0.11993407 |\n","|    std                | 1.01        |\n","|    value_loss         | 1.29        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 3100      |\n","|    time_elapsed       | 103       |\n","|    total_timesteps    | 15500     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0.00341   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3099      |\n","|    policy_loss        | 24.7      |\n","|    reward             | 3.2911394 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.753     |\n","-------------------------------------\n","Episode: 14\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 3200      |\n","|    time_elapsed       | 106       |\n","|    total_timesteps    | 16000     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3199      |\n","|    policy_loss        | -34.8     |\n","|    reward             | 0.5195942 |\n","|    std                | 1.01      |\n","|    value_loss         | 1.67      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 148       |\n","|    iterations         | 3300      |\n","|    time_elapsed       | 110       |\n","|    total_timesteps    | 16500     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0.0882    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3299      |\n","|    policy_loss        | 14.2      |\n","|    reward             | 1.6108916 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.63      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 148       |\n","|    iterations         | 3400      |\n","|    time_elapsed       | 114       |\n","|    total_timesteps    | 17000     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0.0457    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3399      |\n","|    policy_loss        | -503      |\n","|    reward             | 2.6750119 |\n","|    std                | 1.01      |\n","|    value_loss         | 160       |\n","-------------------------------------\n","Episode: 15\n","day: 1133, episode: 15\n","begin_total_asset: 1000000.00\n","end_total_asset: 1440125.71\n","total_reward: 440125.71\n","total_cost: 6183.76\n","total_trades: 13888\n","Sharpe: 0.422\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 3500      |\n","|    time_elapsed       | 117       |\n","|    total_timesteps    | 17500     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3499      |\n","|    policy_loss        | -29.7     |\n","|    reward             | 1.7939246 |\n","|    std                | 1.01      |\n","|    value_loss         | 1.66      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 3600      |\n","|    time_elapsed       | 120       |\n","|    total_timesteps    | 18000     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3599      |\n","|    policy_loss        | -351      |\n","|    reward             | 3.6152906 |\n","|    std                | 1.01      |\n","|    value_loss         | 86        |\n","-------------------------------------\n","Episode: 16\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 3700      |\n","|    time_elapsed       | 123       |\n","|    total_timesteps    | 18500     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3699      |\n","|    policy_loss        | -55.3     |\n","|    reward             | 1.8678969 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.23      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 148        |\n","|    iterations         | 3800       |\n","|    time_elapsed       | 127        |\n","|    total_timesteps    | 19000      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0.0394     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3799       |\n","|    policy_loss        | -6.25      |\n","|    reward             | 0.08540059 |\n","|    std                | 1.01       |\n","|    value_loss         | 2.32       |\n","--------------------------------------\n","Episode: 17\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 149       |\n","|    iterations         | 3900      |\n","|    time_elapsed       | 130       |\n","|    total_timesteps    | 19500     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0.0141    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3899      |\n","|    policy_loss        | 47.6      |\n","|    reward             | 1.1452997 |\n","|    std                | 1.01      |\n","|    value_loss         | 4.07      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 149        |\n","|    iterations         | 4000       |\n","|    time_elapsed       | 133        |\n","|    total_timesteps    | 20000      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0.0621     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3999       |\n","|    policy_loss        | 257        |\n","|    reward             | -1.0376451 |\n","|    std                | 1.02       |\n","|    value_loss         | 48.3       |\n","--------------------------------------\n","======a2c Validation from:  2022-07-06 to  2022-10-04\n","Episode: 1\n","a2c Sharpe Ratio:  -0.08096823210233113\n","======ddpg Training========\n","{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n","Using cuda device\n","Logging to tensorboard_log//ddpg/ddpg_252_1\n","Episode: 19\n","Episode: 20\n","day: 1133, episode: 20\n","begin_total_asset: 1000000.00\n","end_total_asset: 1288311.24\n","total_reward: 288311.24\n","total_cost: 1241.75\n","total_trades: 14728\n","Sharpe: 0.370\n","=================================\n","Episode: 21\n","Episode: 22\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 4           |\n","|    fps             | 83          |\n","|    time_elapsed    | 54          |\n","|    total_timesteps | 4536        |\n","| train/             |             |\n","|    actor_loss      | -48.5       |\n","|    critic_loss     | 45.7        |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 4435        |\n","|    reward          | -0.18748625 |\n","------------------------------------\n","Episode: 23\n","Episode: 24\n","Episode: 25\n","day: 1133, episode: 25\n","begin_total_asset: 1000000.00\n","end_total_asset: 1288311.24\n","total_reward: 288311.24\n","total_cost: 1241.75\n","total_trades: 14728\n","Sharpe: 0.370\n","=================================\n","Episode: 26\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 8           |\n","|    fps             | 83          |\n","|    time_elapsed    | 109         |\n","|    total_timesteps | 9072        |\n","| train/             |             |\n","|    actor_loss      | -31.4       |\n","|    critic_loss     | 3.47        |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 8971        |\n","|    reward          | -0.18748625 |\n","------------------------------------\n","Episode: 27\n","Episode: 28\n","Episode: 29\n","Episode: 30\n","day: 1133, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 1288311.24\n","total_reward: 288311.24\n","total_cost: 1241.75\n","total_trades: 14728\n","Sharpe: 0.370\n","=================================\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 12          |\n","|    fps             | 82          |\n","|    time_elapsed    | 165         |\n","|    total_timesteps | 13608       |\n","| train/             |             |\n","|    actor_loss      | -25.1       |\n","|    critic_loss     | 0.339       |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 13507       |\n","|    reward          | -0.18748625 |\n","------------------------------------\n","Episode: 31\n","Episode: 32\n","Episode: 33\n","Episode: 34\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 16          |\n","|    fps             | 82          |\n","|    time_elapsed    | 220         |\n","|    total_timesteps | 18144       |\n","| train/             |             |\n","|    actor_loss      | -19.8       |\n","|    critic_loss     | 11.3        |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 18043       |\n","|    reward          | -0.18748625 |\n","------------------------------------\n","Episode: 35\n","day: 1133, episode: 35\n","begin_total_asset: 1000000.00\n","end_total_asset: 1288311.24\n","total_reward: 288311.24\n","total_cost: 1241.75\n","total_trades: 14728\n","Sharpe: 0.370\n","=================================\n","======ddpg Validation from:  2022-07-06 to  2022-10-04\n","Episode: 1\n","ddpg Sharpe Ratio:  -0.09442759144010074\n","======ppo Training========\n","{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cuda device\n","Logging to tensorboard_log//ppo/ppo_252_1\n","Episode: 37\n","------------------------------------\n","| time/              |             |\n","|    fps             | 169         |\n","|    iterations      | 1           |\n","|    time_elapsed    | 12          |\n","|    total_timesteps | 2048        |\n","| train/             |             |\n","|    reward          | -0.44889677 |\n","------------------------------------\n","Episode: 38\n","Episode: 39\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 163         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 25          |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.017557295 |\n","|    clip_fraction        | 0.212       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.0352     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.84        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.043      |\n","|    reward               | 1.4011319   |\n","|    std                  | 1           |\n","|    value_loss           | 10.5        |\n","-----------------------------------------\n","Episode: 40\n","day: 1133, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 1073463.80\n","total_reward: 73463.80\n","total_cost: 210013.46\n","total_trades: 30150\n","Sharpe: 0.181\n","=================================\n","Episode: 41\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 162         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 37          |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.015433239 |\n","|    clip_fraction        | 0.173       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.00751    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.31        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0339     |\n","|    reward               | -0.35900193 |\n","|    std                  | 1           |\n","|    value_loss           | 10.7        |\n","-----------------------------------------\n","Episode: 42\n","Episode: 43\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 161         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 50          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.023285493 |\n","|    clip_fraction        | 0.267       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | 0.00768     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.3         |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0431     |\n","|    reward               | 0.4479202   |\n","|    std                  | 1.01        |\n","|    value_loss           | 9.46        |\n","-----------------------------------------\n","Episode: 44\n","Episode: 45\n","day: 1133, episode: 45\n","begin_total_asset: 1000000.00\n","end_total_asset: 1152031.24\n","total_reward: 152031.24\n","total_cost: 215905.24\n","total_trades: 29985\n","Sharpe: 0.254\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 161         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 63          |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.019747544 |\n","|    clip_fraction        | 0.233       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | 0.016       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.53        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0395     |\n","|    reward               | -0.43758044 |\n","|    std                  | 1.01        |\n","|    value_loss           | 13.3        |\n","-----------------------------------------\n","Episode: 46\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 161         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 75          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.019439176 |\n","|    clip_fraction        | 0.242       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | -0.0559     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.83        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.033      |\n","|    reward               | 1.3336434   |\n","|    std                  | 1.01        |\n","|    value_loss           | 14.5        |\n","-----------------------------------------\n","Episode: 47\n","Episode: 48\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 162        |\n","|    iterations           | 7          |\n","|    time_elapsed         | 88         |\n","|    total_timesteps      | 14336      |\n","| train/                  |            |\n","|    approx_kl            | 0.01946526 |\n","|    clip_fraction        | 0.223      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.5      |\n","|    explained_variance   | 0.0983     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 5.59       |\n","|    n_updates            | 60         |\n","|    policy_gradient_loss | -0.033     |\n","|    reward               | -1.0365024 |\n","|    std                  | 1.01       |\n","|    value_loss           | 10         |\n","----------------------------------------\n","Episode: 49\n","Episode: 50\n","day: 1133, episode: 50\n","begin_total_asset: 1000000.00\n","end_total_asset: 1225396.07\n","total_reward: 225396.07\n","total_cost: 209767.28\n","total_trades: 29800\n","Sharpe: 0.317\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 161         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 101         |\n","|    total_timesteps      | 16384       |\n","| train/                  |             |\n","|    approx_kl            | 0.029278953 |\n","|    clip_fraction        | 0.256       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | -0.124      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.29        |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.0353     |\n","|    reward               | 0.9568356   |\n","|    std                  | 1.02        |\n","|    value_loss           | 12.2        |\n","-----------------------------------------\n","Episode: 51\n","Episode: 52\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 161         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 114         |\n","|    total_timesteps      | 18432       |\n","| train/                  |             |\n","|    approx_kl            | 0.023084965 |\n","|    clip_fraction        | 0.253       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | 0.0498      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.79        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.0316     |\n","|    reward               | 0.11508082  |\n","|    std                  | 1.02        |\n","|    value_loss           | 10.1        |\n","-----------------------------------------\n","Episode: 53\n","Episode: 54\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 160         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 127         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.016232338 |\n","|    clip_fraction        | 0.18        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.7       |\n","|    explained_variance   | 0.0593      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.27        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0299     |\n","|    reward               | -1.006085   |\n","|    std                  | 1.02        |\n","|    value_loss           | 15.1        |\n","-----------------------------------------\n","======ppo Validation from:  2022-07-06 to  2022-10-04\n","Episode: 1\n","ppo Sharpe Ratio:  -0.18552878247633747\n","======Best Model Retraining from:  2018-01-01 to  2022-10-04\n","======Trading from:  2022-10-04 to  2023-01-04\n","Used Model:  <stable_baselines3.a2c.a2c.A2C object at 0x7b6b2739db40>\n","Episode: 1\n","============================================\n","turbulence_threshold:  354.94325460158456\n","======Model training from:  2018-01-01 to  2022-10-04\n","==============Model Training===========\n","======a2c Training========\n","{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n","Using cuda device\n","Logging to tensorboard_log//a2c/a2c_315_1\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 150        |\n","|    iterations         | 100        |\n","|    time_elapsed       | 3          |\n","|    total_timesteps    | 500        |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | -0.741     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 99         |\n","|    policy_loss        | 17.1       |\n","|    reward             | 0.14626473 |\n","|    std                | 0.998      |\n","|    value_loss         | 0.808      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 127       |\n","|    iterations         | 200       |\n","|    time_elapsed       | 7         |\n","|    total_timesteps    | 1000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0.211     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 199       |\n","|    policy_loss        | -82.4     |\n","|    reward             | 3.6467595 |\n","|    std                | 0.999     |\n","|    value_loss         | 4.58      |\n","-------------------------------------\n","Episode: 1\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 136        |\n","|    iterations         | 300        |\n","|    time_elapsed       | 11         |\n","|    total_timesteps    | 1500       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -0.0567    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 299        |\n","|    policy_loss        | 1.59       |\n","|    reward             | 0.61411303 |\n","|    std                | 1          |\n","|    value_loss         | 0.524      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 140        |\n","|    iterations         | 400        |\n","|    time_elapsed       | 14         |\n","|    total_timesteps    | 2000       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -0.0215    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 399        |\n","|    policy_loss        | -29.7      |\n","|    reward             | -1.4144266 |\n","|    std                | 1          |\n","|    value_loss         | 9.77       |\n","--------------------------------------\n","Episode: 2\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 143        |\n","|    iterations         | 500        |\n","|    time_elapsed       | 17         |\n","|    total_timesteps    | 2500       |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | -0.285     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 499        |\n","|    policy_loss        | -87        |\n","|    reward             | 0.17258134 |\n","|    std                | 1          |\n","|    value_loss         | 4.76       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 136        |\n","|    iterations         | 600        |\n","|    time_elapsed       | 21         |\n","|    total_timesteps    | 3000       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -0.198     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 599        |\n","|    policy_loss        | 71.6       |\n","|    reward             | 0.78176075 |\n","|    std                | 1          |\n","|    value_loss         | 7.28       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 700         |\n","|    time_elapsed       | 25          |\n","|    total_timesteps    | 3500        |\n","| train/                |             |\n","|    entropy_loss       | -41.2       |\n","|    explained_variance | 0.0596      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 699         |\n","|    policy_loss        | 116         |\n","|    reward             | -0.55366224 |\n","|    std                | 1           |\n","|    value_loss         | 9.53        |\n","---------------------------------------\n","Episode: 3\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 140        |\n","|    iterations         | 800        |\n","|    time_elapsed       | 28         |\n","|    total_timesteps    | 4000       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0.0358     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 799        |\n","|    policy_loss        | -24.3      |\n","|    reward             | 0.16775064 |\n","|    std                | 1          |\n","|    value_loss         | 2.14       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 142        |\n","|    iterations         | 900        |\n","|    time_elapsed       | 31         |\n","|    total_timesteps    | 4500       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 899        |\n","|    policy_loss        | -25.2      |\n","|    reward             | -1.2676444 |\n","|    std                | 1          |\n","|    value_loss         | 1.9        |\n","--------------------------------------\n","Episode: 4\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 137         |\n","|    iterations         | 1000        |\n","|    time_elapsed       | 36          |\n","|    total_timesteps    | 5000        |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | 0.0664      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 999         |\n","|    policy_loss        | -105        |\n","|    reward             | -0.25096077 |\n","|    std                | 1.01        |\n","|    value_loss         | 10          |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 138       |\n","|    iterations         | 1100      |\n","|    time_elapsed       | 39        |\n","|    total_timesteps    | 5500      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | -0.0525   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1099      |\n","|    policy_loss        | -34.6     |\n","|    reward             | 1.5035845 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.36      |\n","-------------------------------------\n","Episode: 5\n","day: 1196, episode: 5\n","begin_total_asset: 1000000.00\n","end_total_asset: 1654055.97\n","total_reward: 654055.97\n","total_cost: 55904.27\n","total_trades: 23968\n","Sharpe: 0.603\n","=================================\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 140         |\n","|    iterations         | 1200        |\n","|    time_elapsed       | 42          |\n","|    total_timesteps    | 6000        |\n","| train/                |             |\n","|    entropy_loss       | -41.4       |\n","|    explained_variance | 1.19e-07    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1199        |\n","|    policy_loss        | 82.4        |\n","|    reward             | -0.04321994 |\n","|    std                | 1.01        |\n","|    value_loss         | 4.13        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 141         |\n","|    iterations         | 1300        |\n","|    time_elapsed       | 45          |\n","|    total_timesteps    | 6500        |\n","| train/                |             |\n","|    entropy_loss       | -41.4       |\n","|    explained_variance | -0.0522     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1299        |\n","|    policy_loss        | 24.5        |\n","|    reward             | -0.87803453 |\n","|    std                | 1.01        |\n","|    value_loss         | 0.45        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 1400       |\n","|    time_elapsed       | 50         |\n","|    total_timesteps    | 7000       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -0.0232    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1399       |\n","|    policy_loss        | 71.9       |\n","|    reward             | 0.49381953 |\n","|    std                | 1.01       |\n","|    value_loss         | 3.86       |\n","--------------------------------------\n","Episode: 6\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 140        |\n","|    iterations         | 1500       |\n","|    time_elapsed       | 53         |\n","|    total_timesteps    | 7500       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0.287      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1499       |\n","|    policy_loss        | 26.8       |\n","|    reward             | -0.8554643 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.789      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 141       |\n","|    iterations         | 1600      |\n","|    time_elapsed       | 56        |\n","|    total_timesteps    | 8000      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0.0713    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1599      |\n","|    policy_loss        | 128       |\n","|    reward             | 2.4761574 |\n","|    std                | 1.01      |\n","|    value_loss         | 10.8      |\n","-------------------------------------\n","Episode: 7\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 142          |\n","|    iterations         | 1700         |\n","|    time_elapsed       | 59           |\n","|    total_timesteps    | 8500         |\n","| train/                |              |\n","|    entropy_loss       | -41.4        |\n","|    explained_variance | 0.195        |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 1699         |\n","|    policy_loss        | -150         |\n","|    reward             | -0.089751184 |\n","|    std                | 1.01         |\n","|    value_loss         | 14.1         |\n","----------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 140       |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 64        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0.0014    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | -148      |\n","|    reward             | 0.7610089 |\n","|    std                | 1.01      |\n","|    value_loss         | 23.5      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 141        |\n","|    iterations         | 1900       |\n","|    time_elapsed       | 67         |\n","|    total_timesteps    | 9500       |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0.0242     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1899       |\n","|    policy_loss        | -112       |\n","|    reward             | 0.27875262 |\n","|    std                | 1.01       |\n","|    value_loss         | 8.7        |\n","--------------------------------------\n","Episode: 8\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 142        |\n","|    iterations         | 2000       |\n","|    time_elapsed       | 70         |\n","|    total_timesteps    | 10000      |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1999       |\n","|    policy_loss        | 16         |\n","|    reward             | -1.1233146 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.913      |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 142      |\n","|    iterations         | 2100     |\n","|    time_elapsed       | 73       |\n","|    total_timesteps    | 10500    |\n","| train/                |          |\n","|    entropy_loss       | -41.4    |\n","|    explained_variance | 1.19e-07 |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 2099     |\n","|    policy_loss        | -89.4    |\n","|    reward             | 1.120885 |\n","|    std                | 1.01     |\n","|    value_loss         | 5.47     |\n","------------------------------------\n","Episode: 9\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 141        |\n","|    iterations         | 2200       |\n","|    time_elapsed       | 77         |\n","|    total_timesteps    | 11000      |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | -0.0206    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2199       |\n","|    policy_loss        | 1.71       |\n","|    reward             | 0.96634823 |\n","|    std                | 1.01       |\n","|    value_loss         | 1.14       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 142       |\n","|    iterations         | 2300      |\n","|    time_elapsed       | 80        |\n","|    total_timesteps    | 11500     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | -0.0244   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2299      |\n","|    policy_loss        | 92.3      |\n","|    reward             | 1.5853539 |\n","|    std                | 1.01      |\n","|    value_loss         | 6.47      |\n","-------------------------------------\n","Episode: 10\n","day: 1196, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 1978779.47\n","total_reward: 978779.47\n","total_cost: 24970.14\n","total_trades: 19842\n","Sharpe: 0.737\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 142       |\n","|    iterations         | 2400      |\n","|    time_elapsed       | 84        |\n","|    total_timesteps    | 12000     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0.0165    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2399      |\n","|    policy_loss        | -109      |\n","|    reward             | 1.5163401 |\n","|    std                | 1.01      |\n","|    value_loss         | 14.7      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 143        |\n","|    iterations         | 2500       |\n","|    time_elapsed       | 87         |\n","|    total_timesteps    | 12500      |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0.0951     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2499       |\n","|    policy_loss        | -13.6      |\n","|    reward             | 0.89247996 |\n","|    std                | 1.01       |\n","|    value_loss         | 3.18       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 141        |\n","|    iterations         | 2600       |\n","|    time_elapsed       | 91         |\n","|    total_timesteps    | 13000      |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | -0.162     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2599       |\n","|    policy_loss        | -92.2      |\n","|    reward             | -2.8758125 |\n","|    std                | 1.01       |\n","|    value_loss         | 6.38       |\n","--------------------------------------\n","Episode: 11\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 142         |\n","|    iterations         | 2700        |\n","|    time_elapsed       | 94          |\n","|    total_timesteps    | 13500       |\n","| train/                |             |\n","|    entropy_loss       | -41.6       |\n","|    explained_variance | -0.00487    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2699        |\n","|    policy_loss        | -53.4       |\n","|    reward             | -0.44386327 |\n","|    std                | 1.02        |\n","|    value_loss         | 1.96        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 142       |\n","|    iterations         | 2800      |\n","|    time_elapsed       | 98        |\n","|    total_timesteps    | 14000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0.0279    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2799      |\n","|    policy_loss        | 25.9      |\n","|    reward             | 1.0723065 |\n","|    std                | 1.02      |\n","|    value_loss         | 0.745     |\n","-------------------------------------\n","Episode: 12\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 143       |\n","|    iterations         | 2900      |\n","|    time_elapsed       | 101       |\n","|    total_timesteps    | 14500     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0.756     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2899      |\n","|    policy_loss        | 20        |\n","|    reward             | 0.7793788 |\n","|    std                | 1.02      |\n","|    value_loss         | 0.426     |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 142       |\n","|    iterations         | 3000      |\n","|    time_elapsed       | 105       |\n","|    total_timesteps    | 15000     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | -0.0202   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2999      |\n","|    policy_loss        | -9.84     |\n","|    reward             | 1.9035616 |\n","|    std                | 1.01      |\n","|    value_loss         | 1.6       |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 142         |\n","|    iterations         | 3100        |\n","|    time_elapsed       | 108         |\n","|    total_timesteps    | 15500       |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | -0.0337     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3099        |\n","|    policy_loss        | -140        |\n","|    reward             | -0.20885871 |\n","|    std                | 1.01        |\n","|    value_loss         | 14.5        |\n","---------------------------------------\n","Episode: 13\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 143        |\n","|    iterations         | 3200       |\n","|    time_elapsed       | 111        |\n","|    total_timesteps    | 16000      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0.00315    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3199       |\n","|    policy_loss        | -38.6      |\n","|    reward             | -1.2136362 |\n","|    std                | 1.01       |\n","|    value_loss         | 1.18       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 143         |\n","|    iterations         | 3300        |\n","|    time_elapsed       | 114         |\n","|    total_timesteps    | 16500       |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | 1.79e-07    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3299        |\n","|    policy_loss        | 42.2        |\n","|    reward             | 0.042230744 |\n","|    std                | 1.01        |\n","|    value_loss         | 2.5         |\n","---------------------------------------\n","Episode: 14\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 143        |\n","|    iterations         | 3400       |\n","|    time_elapsed       | 118        |\n","|    total_timesteps    | 17000      |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0.194      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3399       |\n","|    policy_loss        | -110       |\n","|    reward             | -1.4292911 |\n","|    std                | 1.01       |\n","|    value_loss         | 11.5       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 142        |\n","|    iterations         | 3500       |\n","|    time_elapsed       | 122        |\n","|    total_timesteps    | 17500      |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | -0.0458    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3499       |\n","|    policy_loss        | 152        |\n","|    reward             | -1.1056336 |\n","|    std                | 1.01       |\n","|    value_loss         | 18.9       |\n","--------------------------------------\n","Episode: 15\n","day: 1196, episode: 15\n","begin_total_asset: 1000000.00\n","end_total_asset: 2307354.25\n","total_reward: 1307354.25\n","total_cost: 42008.14\n","total_trades: 20303\n","Sharpe: 0.789\n","=================================\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 143         |\n","|    iterations         | 3600        |\n","|    time_elapsed       | 125         |\n","|    total_timesteps    | 18000       |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | 0.0594      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3599        |\n","|    policy_loss        | -85.8       |\n","|    reward             | 0.020650238 |\n","|    std                | 1.01        |\n","|    value_loss         | 5.62        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 143       |\n","|    iterations         | 3700      |\n","|    time_elapsed       | 128       |\n","|    total_timesteps    | 18500     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0.0929    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3699      |\n","|    policy_loss        | -394      |\n","|    reward             | 9.4657755 |\n","|    std                | 1.01      |\n","|    value_loss         | 115       |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 143      |\n","|    iterations         | 3800     |\n","|    time_elapsed       | 132      |\n","|    total_timesteps    | 19000    |\n","| train/                |          |\n","|    entropy_loss       | -41.5    |\n","|    explained_variance | -0.0413  |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 3799     |\n","|    policy_loss        | -158     |\n","|    reward             | 6.042685 |\n","|    std                | 1.01     |\n","|    value_loss         | 16.9     |\n","------------------------------------\n","Episode: 16\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 142         |\n","|    iterations         | 3900        |\n","|    time_elapsed       | 136         |\n","|    total_timesteps    | 19500       |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | 0.177       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3899        |\n","|    policy_loss        | -39.1       |\n","|    reward             | 0.056399565 |\n","|    std                | 1.01        |\n","|    value_loss         | 1.52        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 143       |\n","|    iterations         | 4000      |\n","|    time_elapsed       | 139       |\n","|    total_timesteps    | 20000     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3999      |\n","|    policy_loss        | 114       |\n","|    reward             | 0.6335037 |\n","|    std                | 1.01      |\n","|    value_loss         | 8.11      |\n","-------------------------------------\n","======a2c Validation from:  2022-10-04 to  2023-01-04\n","Episode: 1\n","a2c Sharpe Ratio:  0.3809918218467061\n","======ddpg Training========\n","{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n","Using cuda device\n","Logging to tensorboard_log//ddpg/ddpg_315_1\n","Episode: 18\n","Episode: 19\n","Episode: 20\n","day: 1196, episode: 20\n","begin_total_asset: 1000000.00\n","end_total_asset: 1376004.22\n","total_reward: 376004.22\n","total_cost: 999.00\n","total_trades: 11949\n","Sharpe: 0.392\n","=================================\n","Episode: 21\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 4         |\n","|    fps             | 82        |\n","|    time_elapsed    | 57        |\n","|    total_timesteps | 4788      |\n","| train/             |           |\n","|    actor_loss      | -4.59     |\n","|    critic_loss     | 7.54e+03  |\n","|    learning_rate   | 0.0005    |\n","|    n_updates       | 4687      |\n","|    reward          | 4.1636667 |\n","----------------------------------\n","Episode: 22\n","Episode: 23\n","Episode: 24\n","Episode: 25\n","day: 1196, episode: 25\n","begin_total_asset: 1000000.00\n","end_total_asset: 1376004.22\n","total_reward: 376004.22\n","total_cost: 999.00\n","total_trades: 11949\n","Sharpe: 0.392\n","=================================\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 8         |\n","|    fps             | 82        |\n","|    time_elapsed    | 115       |\n","|    total_timesteps | 9576      |\n","| train/             |           |\n","|    actor_loss      | 15.6      |\n","|    critic_loss     | 2.18      |\n","|    learning_rate   | 0.0005    |\n","|    n_updates       | 9475      |\n","|    reward          | 4.1636667 |\n","----------------------------------\n","Episode: 26\n","Episode: 27\n","Episode: 28\n","Episode: 29\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 12        |\n","|    fps             | 82        |\n","|    time_elapsed    | 173       |\n","|    total_timesteps | 14364     |\n","| train/             |           |\n","|    actor_loss      | 11        |\n","|    critic_loss     | 0.661     |\n","|    learning_rate   | 0.0005    |\n","|    n_updates       | 14263     |\n","|    reward          | 4.1636667 |\n","----------------------------------\n","Episode: 30\n","day: 1196, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 1376004.22\n","total_reward: 376004.22\n","total_cost: 999.00\n","total_trades: 11949\n","Sharpe: 0.392\n","=================================\n","Episode: 31\n","Episode: 32\n","Episode: 33\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 16        |\n","|    fps             | 82        |\n","|    time_elapsed    | 231       |\n","|    total_timesteps | 19152     |\n","| train/             |           |\n","|    actor_loss      | 8.05      |\n","|    critic_loss     | 0.209     |\n","|    learning_rate   | 0.0005    |\n","|    n_updates       | 19051     |\n","|    reward          | 4.1636667 |\n","----------------------------------\n","======ddpg Validation from:  2022-10-04 to  2023-01-04\n","Episode: 1\n","ddpg Sharpe Ratio:  0.35839916368634406\n","======ppo Training========\n","{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cuda device\n","Logging to tensorboard_log//ppo/ppo_315_1\n","Episode: 35\n","day: 1196, episode: 35\n","begin_total_asset: 1000000.00\n","end_total_asset: 1179831.11\n","total_reward: 179831.11\n","total_cost: 227925.68\n","total_trades: 31790\n","Sharpe: 0.268\n","=================================\n","---------------------------------\n","| time/              |          |\n","|    fps             | 157      |\n","|    iterations      | 1        |\n","|    time_elapsed    | 13       |\n","|    total_timesteps | 2048     |\n","| train/             |          |\n","|    reward          | 0.522331 |\n","---------------------------------\n","Episode: 36\n","Episode: 37\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 154        |\n","|    iterations           | 2          |\n","|    time_elapsed         | 26         |\n","|    total_timesteps      | 4096       |\n","| train/                  |            |\n","|    approx_kl            | 0.01519271 |\n","|    clip_fraction        | 0.208      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.2      |\n","|    explained_variance   | 0.0238     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 4.48       |\n","|    n_updates            | 10         |\n","|    policy_gradient_loss | -0.0408    |\n","|    reward               | 0.52504486 |\n","|    std                  | 1          |\n","|    value_loss           | 12.5       |\n","----------------------------------------\n","Episode: 38\n","Episode: 39\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 154         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 39          |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.015254658 |\n","|    clip_fraction        | 0.16        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.0058     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.03        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0355     |\n","|    reward               | 0.23184647  |\n","|    std                  | 1           |\n","|    value_loss           | 11.8        |\n","-----------------------------------------\n","Episode: 40\n","day: 1196, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 1180267.62\n","total_reward: 180267.62\n","total_cost: 230177.44\n","total_trades: 31912\n","Sharpe: 0.272\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 154         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 52          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.019464713 |\n","|    clip_fraction        | 0.215       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | -0.0307     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.29        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0392     |\n","|    reward               | -0.64106494 |\n","|    std                  | 1.01        |\n","|    value_loss           | 12.9        |\n","-----------------------------------------\n","Episode: 41\n","Episode: 42\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 154        |\n","|    iterations           | 5          |\n","|    time_elapsed         | 66         |\n","|    total_timesteps      | 10240      |\n","| train/                  |            |\n","|    approx_kl            | 0.02018732 |\n","|    clip_fraction        | 0.23       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.4      |\n","|    explained_variance   | 0.0447     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 6.82       |\n","|    n_updates            | 40         |\n","|    policy_gradient_loss | -0.0342    |\n","|    reward               | 0.10336222 |\n","|    std                  | 1.01       |\n","|    value_loss           | 13.4       |\n","----------------------------------------\n","Episode: 43\n","Episode: 44\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 157         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 78          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.016562084 |\n","|    clip_fraction        | 0.177       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | 0.0699      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.44        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.0371     |\n","|    reward               | -0.547211   |\n","|    std                  | 1.01        |\n","|    value_loss           | 12.9        |\n","-----------------------------------------\n","Episode: 45\n","day: 1196, episode: 45\n","begin_total_asset: 1000000.00\n","end_total_asset: 1058921.29\n","total_reward: 58921.29\n","total_cost: 221421.37\n","total_trades: 31431\n","Sharpe: 0.163\n","=================================\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 158        |\n","|    iterations           | 7          |\n","|    time_elapsed         | 90         |\n","|    total_timesteps      | 14336      |\n","| train/                  |            |\n","|    approx_kl            | 0.02122064 |\n","|    clip_fraction        | 0.237      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.5      |\n","|    explained_variance   | 0.0192     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 5.45       |\n","|    n_updates            | 60         |\n","|    policy_gradient_loss | -0.0384    |\n","|    reward               | 0.21869291 |\n","|    std                  | 1.01       |\n","|    value_loss           | 10.5       |\n","----------------------------------------\n","Episode: 46\n","Episode: 47\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 158         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 103         |\n","|    total_timesteps      | 16384       |\n","| train/                  |             |\n","|    approx_kl            | 0.024467133 |\n","|    clip_fraction        | 0.235       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | 0.0574      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.67        |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.0356     |\n","|    reward               | -0.4841001  |\n","|    std                  | 1.02        |\n","|    value_loss           | 10.9        |\n","-----------------------------------------\n","Episode: 48\n","Episode: 49\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 158         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 116         |\n","|    total_timesteps      | 18432       |\n","| train/                  |             |\n","|    approx_kl            | 0.021430984 |\n","|    clip_fraction        | 0.216       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | 0.0208      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.76        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.0396     |\n","|    reward               | 0.45778367  |\n","|    std                  | 1.02        |\n","|    value_loss           | 11.2        |\n","-----------------------------------------\n","Episode: 50\n","day: 1196, episode: 50\n","begin_total_asset: 1000000.00\n","end_total_asset: 1098526.11\n","total_reward: 98526.11\n","total_cost: 214811.36\n","total_trades: 31277\n","Sharpe: 0.200\n","=================================\n","Episode: 51\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 158         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 129         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.021154374 |\n","|    clip_fraction        | 0.237       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | -0.0158     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.25        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0358     |\n","|    reward               | -0.80007017 |\n","|    std                  | 1.02        |\n","|    value_loss           | 8.99        |\n","-----------------------------------------\n","======ppo Validation from:  2022-10-04 to  2023-01-04\n","Episode: 1\n","ppo Sharpe Ratio:  0.18812006385003913\n","======Best Model Retraining from:  2018-01-01 to  2023-01-04\n","======Trading from:  2023-01-04 to  2023-04-05\n","Used Model:  <stable_baselines3.a2c.a2c.A2C object at 0x7b6b70424c10>\n","Episode: 1\n","============================================\n","turbulence_threshold:  354.94325460158456\n","======Model training from:  2018-01-01 to  2023-01-04\n","==============Model Training===========\n","======a2c Training========\n","{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n","Using cuda device\n","Logging to tensorboard_log//a2c/a2c_378_1\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 140         |\n","|    iterations         | 100         |\n","|    time_elapsed       | 3           |\n","|    total_timesteps    | 500         |\n","| train/                |             |\n","|    entropy_loss       | -41.1       |\n","|    explained_variance | 0.471       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 99          |\n","|    policy_loss        | 28.2        |\n","|    reward             | 0.040708043 |\n","|    std                | 0.999       |\n","|    value_loss         | 0.65        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 125       |\n","|    iterations         | 200       |\n","|    time_elapsed       | 7         |\n","|    total_timesteps    | 1000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0.122     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 199       |\n","|    policy_loss        | -12.7     |\n","|    reward             | 3.1742396 |\n","|    std                | 0.999     |\n","|    value_loss         | 0.398     |\n","-------------------------------------\n","Episode: 1\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 300        |\n","|    time_elapsed       | 11         |\n","|    total_timesteps    | 1500       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0.409      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 299        |\n","|    policy_loss        | -218       |\n","|    reward             | -3.2328053 |\n","|    std                | 1          |\n","|    value_loss         | 29.2       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 400        |\n","|    time_elapsed       | 14         |\n","|    total_timesteps    | 2000       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0.248      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 399        |\n","|    policy_loss        | 46         |\n","|    reward             | 0.05622389 |\n","|    std                | 1          |\n","|    value_loss         | 1.73       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 500        |\n","|    time_elapsed       | 18         |\n","|    total_timesteps    | 2500       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -0.245     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 499        |\n","|    policy_loss        | -46.3      |\n","|    reward             | -0.9226671 |\n","|    std                | 1          |\n","|    value_loss         | 1.94       |\n","--------------------------------------\n","Episode: 2\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 600        |\n","|    time_elapsed       | 22         |\n","|    total_timesteps    | 3000       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -0.539     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 599        |\n","|    policy_loss        | 97.6       |\n","|    reward             | 0.07115997 |\n","|    std                | 1          |\n","|    value_loss         | 6.77       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 136         |\n","|    iterations         | 700         |\n","|    time_elapsed       | 25          |\n","|    total_timesteps    | 3500        |\n","| train/                |             |\n","|    entropy_loss       | -41.2       |\n","|    explained_variance | 0.315       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 699         |\n","|    policy_loss        | -67.5       |\n","|    reward             | -0.70185906 |\n","|    std                | 1           |\n","|    value_loss         | 2.75        |\n","---------------------------------------\n","Episode: 3\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 137        |\n","|    iterations         | 800        |\n","|    time_elapsed       | 29         |\n","|    total_timesteps    | 4000       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -0.553     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 799        |\n","|    policy_loss        | 134        |\n","|    reward             | -0.3533295 |\n","|    std                | 1          |\n","|    value_loss         | 9.98       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 137       |\n","|    iterations         | 900       |\n","|    time_elapsed       | 32        |\n","|    total_timesteps    | 4500      |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | 0.0937    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 899       |\n","|    policy_loss        | 71        |\n","|    reward             | 0.2670328 |\n","|    std                | 1         |\n","|    value_loss         | 5.2       |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 135       |\n","|    iterations         | 1000      |\n","|    time_elapsed       | 36        |\n","|    total_timesteps    | 5000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0.0145    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 999       |\n","|    policy_loss        | 162       |\n","|    reward             | 1.5246124 |\n","|    std                | 1         |\n","|    value_loss         | 15.3      |\n","-------------------------------------\n","Episode: 4\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 137        |\n","|    iterations         | 1100       |\n","|    time_elapsed       | 40         |\n","|    total_timesteps    | 5500       |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | -0.102     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1099       |\n","|    policy_loss        | -40.4      |\n","|    reward             | 0.63465333 |\n","|    std                | 0.999      |\n","|    value_loss         | 1.1        |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 1200        |\n","|    time_elapsed       | 43          |\n","|    total_timesteps    | 6000        |\n","| train/                |             |\n","|    entropy_loss       | -41.2       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1199        |\n","|    policy_loss        | 10.1        |\n","|    reward             | -0.05818446 |\n","|    std                | 1           |\n","|    value_loss         | 1.89        |\n","---------------------------------------\n","Episode: 5\n","day: 1259, episode: 5\n","begin_total_asset: 1000000.00\n","end_total_asset: 1007029.34\n","total_reward: 7029.34\n","total_cost: 116391.63\n","total_trades: 27166\n","Sharpe: 0.112\n","=================================\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 137          |\n","|    iterations         | 1300         |\n","|    time_elapsed       | 47           |\n","|    total_timesteps    | 6500         |\n","| train/                |              |\n","|    entropy_loss       | -41.2        |\n","|    explained_variance | 0.281        |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 1299         |\n","|    policy_loss        | -186         |\n","|    reward             | -0.008416339 |\n","|    std                | 1            |\n","|    value_loss         | 21.6         |\n","----------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 135        |\n","|    iterations         | 1400       |\n","|    time_elapsed       | 51         |\n","|    total_timesteps    | 7000       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0.222      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1399       |\n","|    policy_loss        | -11.6      |\n","|    reward             | -1.4322771 |\n","|    std                | 1          |\n","|    value_loss         | 0.495      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 136        |\n","|    iterations         | 1500       |\n","|    time_elapsed       | 54         |\n","|    total_timesteps    | 7500       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0.000242   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1499       |\n","|    policy_loss        | -56.6      |\n","|    reward             | -2.3262532 |\n","|    std                | 1          |\n","|    value_loss         | 3.96       |\n","--------------------------------------\n","Episode: 6\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 137        |\n","|    iterations         | 1600       |\n","|    time_elapsed       | 58         |\n","|    total_timesteps    | 8000       |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1599       |\n","|    policy_loss        | -10.3      |\n","|    reward             | -2.8308003 |\n","|    std                | 1          |\n","|    value_loss         | 0.17       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 136         |\n","|    iterations         | 1700        |\n","|    time_elapsed       | 62          |\n","|    total_timesteps    | 8500        |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1699        |\n","|    policy_loss        | -69.2       |\n","|    reward             | 0.079387374 |\n","|    std                | 1           |\n","|    value_loss         | 3.39        |\n","---------------------------------------\n","Episode: 7\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 136       |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 66        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | 30.3      |\n","|    reward             | 0.3016871 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.626     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 137        |\n","|    iterations         | 1900       |\n","|    time_elapsed       | 69         |\n","|    total_timesteps    | 9500       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | -0.45      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1899       |\n","|    policy_loss        | -55.7      |\n","|    reward             | 0.21898516 |\n","|    std                | 1.01       |\n","|    value_loss         | 2.31       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 138       |\n","|    iterations         | 2000      |\n","|    time_elapsed       | 72        |\n","|    total_timesteps    | 10000     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1999      |\n","|    policy_loss        | -62.4     |\n","|    reward             | 1.1194303 |\n","|    std                | 1.01      |\n","|    value_loss         | 4.26      |\n","-------------------------------------\n","Episode: 8\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 137       |\n","|    iterations         | 2100      |\n","|    time_elapsed       | 76        |\n","|    total_timesteps    | 10500     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2099      |\n","|    policy_loss        | -12.3     |\n","|    reward             | 1.3772398 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.846     |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 136       |\n","|    iterations         | 2200      |\n","|    time_elapsed       | 80        |\n","|    total_timesteps    | 11000     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2199      |\n","|    policy_loss        | -10.4     |\n","|    reward             | 0.8327718 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.831     |\n","-------------------------------------\n","Episode: 9\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 137         |\n","|    iterations         | 2300        |\n","|    time_elapsed       | 83          |\n","|    total_timesteps    | 11500       |\n","| train/                |             |\n","|    entropy_loss       | -41.4       |\n","|    explained_variance | -0.447      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2299        |\n","|    policy_loss        | 40.6        |\n","|    reward             | 0.078359835 |\n","|    std                | 1.01        |\n","|    value_loss         | 1.11        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 2400        |\n","|    time_elapsed       | 86          |\n","|    total_timesteps    | 12000       |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2399        |\n","|    policy_loss        | 106         |\n","|    reward             | -0.26724213 |\n","|    std                | 1.01        |\n","|    value_loss         | 7.53        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 2500        |\n","|    time_elapsed       | 90          |\n","|    total_timesteps    | 12500       |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | 0.0785      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2499        |\n","|    policy_loss        | -14         |\n","|    reward             | -0.08799735 |\n","|    std                | 1.01        |\n","|    value_loss         | 0.481       |\n","---------------------------------------\n","Episode: 10\n","day: 1259, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 1012584.26\n","total_reward: 12584.26\n","total_cost: 50318.54\n","total_trades: 22747\n","Sharpe: 0.115\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 137       |\n","|    iterations         | 2600      |\n","|    time_elapsed       | 94        |\n","|    total_timesteps    | 13000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0.479     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2599      |\n","|    policy_loss        | 15.4      |\n","|    reward             | 1.3491892 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.219     |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 2700        |\n","|    time_elapsed       | 97          |\n","|    total_timesteps    | 13500       |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | -0.00302    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2699        |\n","|    policy_loss        | 101         |\n","|    reward             | -0.24080516 |\n","|    std                | 1.01        |\n","|    value_loss         | 7.68        |\n","---------------------------------------\n","Episode: 11\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 2800       |\n","|    time_elapsed       | 100        |\n","|    total_timesteps    | 14000      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | -4.32      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2799       |\n","|    policy_loss        | -29.3      |\n","|    reward             | 0.49561355 |\n","|    std                | 1.02       |\n","|    value_loss         | 2.12       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 2900        |\n","|    time_elapsed       | 104         |\n","|    total_timesteps    | 14500       |\n","| train/                |             |\n","|    entropy_loss       | -41.6       |\n","|    explained_variance | -0.0365     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2899        |\n","|    policy_loss        | 30.8        |\n","|    reward             | 0.025578134 |\n","|    std                | 1.02        |\n","|    value_loss         | 1.28        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 137         |\n","|    iterations         | 3000        |\n","|    time_elapsed       | 108         |\n","|    total_timesteps    | 15000       |\n","| train/                |             |\n","|    entropy_loss       | -41.7       |\n","|    explained_variance | 0.0251      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2999        |\n","|    policy_loss        | 71.4        |\n","|    reward             | -0.21952175 |\n","|    std                | 1.02        |\n","|    value_loss         | 3.22        |\n","---------------------------------------\n","Episode: 12\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 3100       |\n","|    time_elapsed       | 112        |\n","|    total_timesteps    | 15500      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0.341      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3099       |\n","|    policy_loss        | 40.2       |\n","|    reward             | 0.19547635 |\n","|    std                | 1.02       |\n","|    value_loss         | 1.31       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 3200       |\n","|    time_elapsed       | 115        |\n","|    total_timesteps    | 16000      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0.0581     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3199       |\n","|    policy_loss        | 15.5       |\n","|    reward             | 0.21623722 |\n","|    std                | 1.02       |\n","|    value_loss         | 1          |\n","--------------------------------------\n","Episode: 13\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 138       |\n","|    iterations         | 3300      |\n","|    time_elapsed       | 119       |\n","|    total_timesteps    | 16500     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0.552     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3299      |\n","|    policy_loss        | -50       |\n","|    reward             | -0.937845 |\n","|    std                | 1.02      |\n","|    value_loss         | 1.65      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 3400        |\n","|    time_elapsed       | 123         |\n","|    total_timesteps    | 17000       |\n","| train/                |             |\n","|    entropy_loss       | -41.8       |\n","|    explained_variance | 0.138       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3399        |\n","|    policy_loss        | -179        |\n","|    reward             | -0.44700202 |\n","|    std                | 1.02        |\n","|    value_loss         | 25.5        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 3500       |\n","|    time_elapsed       | 126        |\n","|    total_timesteps    | 17500      |\n","| train/                |            |\n","|    entropy_loss       | -41.8      |\n","|    explained_variance | -0.0546    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3499       |\n","|    policy_loss        | 49.9       |\n","|    reward             | -1.3174173 |\n","|    std                | 1.02       |\n","|    value_loss         | 2.11       |\n","--------------------------------------\n","Episode: 14\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 138          |\n","|    iterations         | 3600         |\n","|    time_elapsed       | 129          |\n","|    total_timesteps    | 18000        |\n","| train/                |              |\n","|    entropy_loss       | -41.8        |\n","|    explained_variance | -0.195       |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 3599         |\n","|    policy_loss        | -33.5        |\n","|    reward             | -0.059121415 |\n","|    std                | 1.02         |\n","|    value_loss         | 1.28         |\n","----------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 3700       |\n","|    time_elapsed       | 133        |\n","|    total_timesteps    | 18500      |\n","| train/                |            |\n","|    entropy_loss       | -41.8      |\n","|    explained_variance | -0.0367    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3699       |\n","|    policy_loss        | 39.9       |\n","|    reward             | -0.7375092 |\n","|    std                | 1.02       |\n","|    value_loss         | 1.41       |\n","--------------------------------------\n","Episode: 15\n","day: 1259, episode: 15\n","begin_total_asset: 1000000.00\n","end_total_asset: 1635074.23\n","total_reward: 635074.23\n","total_cost: 63898.00\n","total_trades: 24866\n","Sharpe: 0.523\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 137        |\n","|    iterations         | 3800       |\n","|    time_elapsed       | 137        |\n","|    total_timesteps    | 19000      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0.453      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3799       |\n","|    policy_loss        | -8.86      |\n","|    reward             | -0.8706649 |\n","|    std                | 1.02       |\n","|    value_loss         | 0.136      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 138        |\n","|    iterations         | 3900       |\n","|    time_elapsed       | 140        |\n","|    total_timesteps    | 19500      |\n","| train/                |            |\n","|    entropy_loss       | -41.8      |\n","|    explained_variance | 0.115      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3899       |\n","|    policy_loss        | -80.1      |\n","|    reward             | -0.5922754 |\n","|    std                | 1.02       |\n","|    value_loss         | 6.34       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 138         |\n","|    iterations         | 4000        |\n","|    time_elapsed       | 144         |\n","|    total_timesteps    | 20000       |\n","| train/                |             |\n","|    entropy_loss       | -41.8       |\n","|    explained_variance | 0.0176      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3999        |\n","|    policy_loss        | -45.5       |\n","|    reward             | 0.034079347 |\n","|    std                | 1.03        |\n","|    value_loss         | 2.65        |\n","---------------------------------------\n","======a2c Validation from:  2023-01-04 to  2023-04-05\n","Episode: 1\n","a2c Sharpe Ratio:  -0.05063233398765869\n","======ddpg Training========\n","{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n","Using cuda device\n","Logging to tensorboard_log//ddpg/ddpg_378_1\n","Episode: 17\n","Episode: 18\n","Episode: 19\n","Episode: 20\n","day: 1259, episode: 20\n","begin_total_asset: 1000000.00\n","end_total_asset: 1666892.23\n","total_reward: 666892.23\n","total_cost: 1601.84\n","total_trades: 21466\n","Sharpe: 0.584\n","=================================\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 4           |\n","|    fps             | 80          |\n","|    time_elapsed    | 62          |\n","|    total_timesteps | 5040        |\n","| train/             |             |\n","|    actor_loss      | 81.2        |\n","|    critic_loss     | 5.52        |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 4939        |\n","|    reward          | -0.45835626 |\n","------------------------------------\n","Episode: 21\n","Episode: 22\n","Episode: 23\n","Episode: 24\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 8           |\n","|    fps             | 80          |\n","|    time_elapsed    | 124         |\n","|    total_timesteps | 10080       |\n","| train/             |             |\n","|    actor_loss      | 61.4        |\n","|    critic_loss     | 0.923       |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 9979        |\n","|    reward          | -0.45835626 |\n","------------------------------------\n","Episode: 25\n","day: 1259, episode: 25\n","begin_total_asset: 1000000.00\n","end_total_asset: 1666892.23\n","total_reward: 666892.23\n","total_cost: 1601.84\n","total_trades: 21466\n","Sharpe: 0.584\n","=================================\n","Episode: 26\n","Episode: 27\n","Episode: 28\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 12          |\n","|    fps             | 80          |\n","|    time_elapsed    | 186         |\n","|    total_timesteps | 15120       |\n","| train/             |             |\n","|    actor_loss      | 49.7        |\n","|    critic_loss     | 0.359       |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 15019       |\n","|    reward          | -0.45835626 |\n","------------------------------------\n","Episode: 29\n","Episode: 30\n","day: 1259, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 1666892.23\n","total_reward: 666892.23\n","total_cost: 1601.84\n","total_trades: 21466\n","Sharpe: 0.584\n","=================================\n","Episode: 31\n","======ddpg Validation from:  2023-01-04 to  2023-04-05\n","Episode: 1\n","ddpg Sharpe Ratio:  0.10767721553144688\n","======ppo Training========\n","{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cuda device\n","Logging to tensorboard_log//ppo/ppo_378_1\n","Episode: 33\n","-----------------------------------\n","| time/              |            |\n","|    fps             | 165        |\n","|    iterations      | 1          |\n","|    time_elapsed    | 12         |\n","|    total_timesteps | 2048       |\n","| train/             |            |\n","|    reward          | 0.20383444 |\n","-----------------------------------\n","Episode: 34\n","Episode: 35\n","day: 1259, episode: 35\n","begin_total_asset: 1000000.00\n","end_total_asset: 1293039.47\n","total_reward: 293039.47\n","total_cost: 244740.32\n","total_trades: 33478\n","Sharpe: 0.345\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 162         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 25          |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.014339352 |\n","|    clip_fraction        | 0.157       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | 0.00383     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.66        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0385     |\n","|    reward               | 0.42451367  |\n","|    std                  | 1           |\n","|    value_loss           | 11.7        |\n","-----------------------------------------\n","Episode: 36\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 161         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 38          |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.017128203 |\n","|    clip_fraction        | 0.195       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | 0.0167      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.15        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0346     |\n","|    reward               | 0.90902376  |\n","|    std                  | 1           |\n","|    value_loss           | 11.4        |\n","-----------------------------------------\n","Episode: 37\n","Episode: 38\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 161         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 50          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.014447281 |\n","|    clip_fraction        | 0.177       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | 0.0452      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 5.18        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0399     |\n","|    reward               | 0.98119956  |\n","|    std                  | 1.01        |\n","|    value_loss           | 13.8        |\n","-----------------------------------------\n","Episode: 39\n","Episode: 40\n","day: 1259, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 1187008.42\n","total_reward: 187008.42\n","total_cost: 233281.68\n","total_trades: 33002\n","Sharpe: 0.269\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 159         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 64          |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.015022691 |\n","|    clip_fraction        | 0.157       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | 0.00419     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.39        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0276     |\n","|    reward               | 0.0623385   |\n","|    std                  | 1.01        |\n","|    value_loss           | 13.4        |\n","-----------------------------------------\n","Episode: 41\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 156         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 78          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.016538307 |\n","|    clip_fraction        | 0.223       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | 0.0673      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.63        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.0389     |\n","|    reward               | 0.73889756  |\n","|    std                  | 1.01        |\n","|    value_loss           | 8.27        |\n","-----------------------------------------\n","Episode: 42\n","Episode: 43\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 156         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 91          |\n","|    total_timesteps      | 14336       |\n","| train/                  |             |\n","|    approx_kl            | 0.0168612   |\n","|    clip_fraction        | 0.192       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | 0.0269      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.28        |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0346     |\n","|    reward               | -0.18044683 |\n","|    std                  | 1.01        |\n","|    value_loss           | 12.5        |\n","-----------------------------------------\n","Episode: 44\n","Episode: 45\n","day: 1259, episode: 45\n","begin_total_asset: 1000000.00\n","end_total_asset: 1279911.86\n","total_reward: 279911.86\n","total_cost: 237103.66\n","total_trades: 33259\n","Sharpe: 0.341\n","=================================\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 155           |\n","|    iterations           | 8             |\n","|    time_elapsed         | 105           |\n","|    total_timesteps      | 16384         |\n","| train/                  |               |\n","|    approx_kl            | 0.01682826    |\n","|    clip_fraction        | 0.209         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -41.4         |\n","|    explained_variance   | 0.0838        |\n","|    learning_rate        | 0.00025       |\n","|    loss                 | 4.05          |\n","|    n_updates            | 70            |\n","|    policy_gradient_loss | -0.0345       |\n","|    reward               | -0.0013094468 |\n","|    std                  | 1.01          |\n","|    value_loss           | 9.08          |\n","-------------------------------------------\n","Episode: 46\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 155         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 118         |\n","|    total_timesteps      | 18432       |\n","| train/                  |             |\n","|    approx_kl            | 0.020093855 |\n","|    clip_fraction        | 0.229       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | 0.0259      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.82        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.0379     |\n","|    reward               | -3.3188252  |\n","|    std                  | 1.01        |\n","|    value_loss           | 13.3        |\n","-----------------------------------------\n","Episode: 47\n","Episode: 48\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 155         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 131         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.018641025 |\n","|    clip_fraction        | 0.18        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | 0.0518      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.17        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0297     |\n","|    reward               | 0.23278928  |\n","|    std                  | 1.01        |\n","|    value_loss           | 13.1        |\n","-----------------------------------------\n","======ppo Validation from:  2023-01-04 to  2023-04-05\n","Episode: 1\n","ppo Sharpe Ratio:  -0.04343392756304305\n","======Best Model Retraining from:  2018-01-01 to  2023-04-05\n","======Trading from:  2023-04-05 to  2023-07-07\n","Used Model:  <stable_baselines3.ddpg.ddpg.DDPG object at 0x7b6aea93db70>\n","Episode: 1\n","============================================\n","turbulence_threshold:  354.94325460158456\n","======Model training from:  2018-01-01 to  2023-04-05\n","==============Model Training===========\n","======a2c Training========\n","{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n","Using cuda device\n","Logging to tensorboard_log//a2c/a2c_441_1\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 152          |\n","|    iterations         | 100          |\n","|    time_elapsed       | 3            |\n","|    total_timesteps    | 500          |\n","| train/                |              |\n","|    entropy_loss       | -41          |\n","|    explained_variance | 0.227        |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 99           |\n","|    policy_loss        | 31.3         |\n","|    reward             | -0.013139802 |\n","|    std                | 0.993        |\n","|    value_loss         | 0.941        |\n","----------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 120      |\n","|    iterations         | 200      |\n","|    time_elapsed       | 8        |\n","|    total_timesteps    | 1000     |\n","| train/                |          |\n","|    entropy_loss       | -41      |\n","|    explained_variance | 0.33     |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 199      |\n","|    policy_loss        | -161     |\n","|    reward             | 4.910251 |\n","|    std                | 0.995    |\n","|    value_loss         | 17.2     |\n","------------------------------------\n","Episode: 1\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 128        |\n","|    iterations         | 300        |\n","|    time_elapsed       | 11         |\n","|    total_timesteps    | 1500       |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | 0.29       |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 299        |\n","|    policy_loss        | 33.9       |\n","|    reward             | 0.68498045 |\n","|    std                | 0.995      |\n","|    value_loss         | 0.794      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 134        |\n","|    iterations         | 400        |\n","|    time_elapsed       | 14         |\n","|    total_timesteps    | 2000       |\n","| train/                |            |\n","|    entropy_loss       | -41        |\n","|    explained_variance | 0.327      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 399        |\n","|    policy_loss        | 63.6       |\n","|    reward             | -1.9320692 |\n","|    std                | 0.996      |\n","|    value_loss         | 2.63       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 137         |\n","|    iterations         | 500         |\n","|    time_elapsed       | 18          |\n","|    total_timesteps    | 2500        |\n","| train/                |             |\n","|    entropy_loss       | -41.1       |\n","|    explained_variance | -0.00948    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 499         |\n","|    policy_loss        | -27.1       |\n","|    reward             | -0.20033635 |\n","|    std                | 0.997       |\n","|    value_loss         | 1.63        |\n","---------------------------------------\n","Episode: 2\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 130       |\n","|    iterations         | 600       |\n","|    time_elapsed       | 23        |\n","|    total_timesteps    | 3000      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0.125     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 599       |\n","|    policy_loss        | -53.2     |\n","|    reward             | -2.134832 |\n","|    std                | 0.997     |\n","|    value_loss         | 1.9       |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 133       |\n","|    iterations         | 700       |\n","|    time_elapsed       | 26        |\n","|    total_timesteps    | 3500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | -0.0157   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 699       |\n","|    policy_loss        | 17.5      |\n","|    reward             | 0.6526897 |\n","|    std                | 0.996     |\n","|    value_loss         | 1.43      |\n","-------------------------------------\n","Episode: 3\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 135      |\n","|    iterations         | 800      |\n","|    time_elapsed       | 29       |\n","|    total_timesteps    | 4000     |\n","| train/                |          |\n","|    entropy_loss       | -41      |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 799      |\n","|    policy_loss        | -188     |\n","|    reward             | 1.841344 |\n","|    std                | 0.996    |\n","|    value_loss         | 23.8     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 136       |\n","|    iterations         | 900       |\n","|    time_elapsed       | 33        |\n","|    total_timesteps    | 4500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0.00518   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 899       |\n","|    policy_loss        | 60.4      |\n","|    reward             | 1.3063159 |\n","|    std                | 0.996     |\n","|    value_loss         | 3.62      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 132      |\n","|    iterations         | 1000     |\n","|    time_elapsed       | 37       |\n","|    total_timesteps    | 5000     |\n","| train/                |          |\n","|    entropy_loss       | -41      |\n","|    explained_variance | 0.351    |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 999      |\n","|    policy_loss        | 109      |\n","|    reward             | 3.14996  |\n","|    std                | 0.997    |\n","|    value_loss         | 6.12     |\n","------------------------------------\n","Episode: 4\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 1100       |\n","|    time_elapsed       | 41         |\n","|    total_timesteps    | 5500       |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | -0.00148   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1099       |\n","|    policy_loss        | -30.6      |\n","|    reward             | 0.21988297 |\n","|    std                | 0.997      |\n","|    value_loss         | 1.92       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 134         |\n","|    iterations         | 1200        |\n","|    time_elapsed       | 44          |\n","|    total_timesteps    | 6000        |\n","| train/                |             |\n","|    entropy_loss       | -41.1       |\n","|    explained_variance | -0.438      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1199        |\n","|    policy_loss        | -53.1       |\n","|    reward             | -0.06581336 |\n","|    std                | 0.998       |\n","|    value_loss         | 2.66        |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 133         |\n","|    iterations         | 1300        |\n","|    time_elapsed       | 48          |\n","|    total_timesteps    | 6500        |\n","| train/                |             |\n","|    entropy_loss       | -41.1       |\n","|    explained_variance | 0.14        |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1299        |\n","|    policy_loss        | -112        |\n","|    reward             | -0.81387514 |\n","|    std                | 0.997       |\n","|    value_loss         | 10.4        |\n","---------------------------------------\n","Episode: 5\n","day: 1322, episode: 5\n","begin_total_asset: 1000000.00\n","end_total_asset: 1519669.55\n","total_reward: 519669.55\n","total_cost: 17971.97\n","total_trades: 22092\n","Sharpe: 0.432\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 132        |\n","|    iterations         | 1400       |\n","|    time_elapsed       | 52         |\n","|    total_timesteps    | 7000       |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | -1.06      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1399       |\n","|    policy_loss        | -0.496     |\n","|    reward             | 0.28942773 |\n","|    std                | 0.998      |\n","|    value_loss         | 0.16       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 133       |\n","|    iterations         | 1500      |\n","|    time_elapsed       | 56        |\n","|    total_timesteps    | 7500      |\n","| train/                |           |\n","|    entropy_loss       | -41       |\n","|    explained_variance | 0.0439    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1499      |\n","|    policy_loss        | 29.6      |\n","|    reward             | 2.1520905 |\n","|    std                | 0.997     |\n","|    value_loss         | 2.21      |\n","-------------------------------------\n","Episode: 6\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 134       |\n","|    iterations         | 1600      |\n","|    time_elapsed       | 59        |\n","|    total_timesteps    | 8000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | 0.224     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1599      |\n","|    policy_loss        | 0.672     |\n","|    reward             | 1.4294888 |\n","|    std                | 0.998     |\n","|    value_loss         | 3.45      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 132      |\n","|    iterations         | 1700     |\n","|    time_elapsed       | 64       |\n","|    total_timesteps    | 8500     |\n","| train/                |          |\n","|    entropy_loss       | -41.1    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 1699     |\n","|    policy_loss        | -302     |\n","|    reward             | -4.25593 |\n","|    std                | 0.997    |\n","|    value_loss         | 74.6     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 132       |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 68        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -41.1     |\n","|    explained_variance | -0.0365   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | 83.7      |\n","|    reward             | 2.8245738 |\n","|    std                | 0.998     |\n","|    value_loss         | 11.4      |\n","-------------------------------------\n","Episode: 7\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 132         |\n","|    iterations         | 1900        |\n","|    time_elapsed       | 71          |\n","|    total_timesteps    | 9500        |\n","| train/                |             |\n","|    entropy_loss       | -41.1       |\n","|    explained_variance | -0.00563    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1899        |\n","|    policy_loss        | -22.4       |\n","|    reward             | 0.037741784 |\n","|    std                | 0.998       |\n","|    value_loss         | 1.33        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 2000       |\n","|    time_elapsed       | 74         |\n","|    total_timesteps    | 10000      |\n","| train/                |            |\n","|    entropy_loss       | -41.1      |\n","|    explained_variance | 0.0884     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1999       |\n","|    policy_loss        | 54.7       |\n","|    reward             | 0.66810215 |\n","|    std                | 0.999      |\n","|    value_loss         | 2.96       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 131         |\n","|    iterations         | 2100        |\n","|    time_elapsed       | 79          |\n","|    total_timesteps    | 10500       |\n","| train/                |             |\n","|    entropy_loss       | -41.1       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2099        |\n","|    policy_loss        | 62.9        |\n","|    reward             | -0.41000184 |\n","|    std                | 1           |\n","|    value_loss         | 4.81        |\n","---------------------------------------\n","Episode: 8\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 132       |\n","|    iterations         | 2200      |\n","|    time_elapsed       | 83        |\n","|    total_timesteps    | 11000     |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | -0.0117   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2199      |\n","|    policy_loss        | 55        |\n","|    reward             | 0.5289777 |\n","|    std                | 1         |\n","|    value_loss         | 3.03      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 2300       |\n","|    time_elapsed       | 86         |\n","|    total_timesteps    | 11500      |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2299       |\n","|    policy_loss        | 89.3       |\n","|    reward             | 0.31009832 |\n","|    std                | 1          |\n","|    value_loss         | 6.54       |\n","--------------------------------------\n","Episode: 9\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 2400       |\n","|    time_elapsed       | 89         |\n","|    total_timesteps    | 12000      |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0.238      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2399       |\n","|    policy_loss        | 57.6       |\n","|    reward             | 0.35788393 |\n","|    std                | 1          |\n","|    value_loss         | 2.57       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 131       |\n","|    iterations         | 2500      |\n","|    time_elapsed       | 94        |\n","|    total_timesteps    | 12500     |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2499      |\n","|    policy_loss        | 50.7      |\n","|    reward             | -2.187525 |\n","|    std                | 1         |\n","|    value_loss         | 3.13      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 132        |\n","|    iterations         | 2600       |\n","|    time_elapsed       | 98         |\n","|    total_timesteps    | 13000      |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | 0.0031     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2599       |\n","|    policy_loss        | 162        |\n","|    reward             | -10.778129 |\n","|    std                | 1          |\n","|    value_loss         | 33.2       |\n","--------------------------------------\n","Episode: 10\n","day: 1322, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 2391835.27\n","total_reward: 1391835.27\n","total_cost: 5935.84\n","total_trades: 23890\n","Sharpe: 0.776\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 133       |\n","|    iterations         | 2700      |\n","|    time_elapsed       | 101       |\n","|    total_timesteps    | 13500     |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | -0.0266   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2699      |\n","|    policy_loss        | 46.6      |\n","|    reward             | 1.5402937 |\n","|    std                | 1         |\n","|    value_loss         | 2.22      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 133      |\n","|    iterations         | 2800     |\n","|    time_elapsed       | 104      |\n","|    total_timesteps    | 14000    |\n","| train/                |          |\n","|    entropy_loss       | -41.2    |\n","|    explained_variance | 0.0157   |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 2799     |\n","|    policy_loss        | -128     |\n","|    reward             | 2.169047 |\n","|    std                | 1        |\n","|    value_loss         | 9.16     |\n","------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 132         |\n","|    iterations         | 2900        |\n","|    time_elapsed       | 109         |\n","|    total_timesteps    | 14500       |\n","| train/                |             |\n","|    entropy_loss       | -41.2       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2899        |\n","|    policy_loss        | 256         |\n","|    reward             | -0.56997496 |\n","|    std                | 1           |\n","|    value_loss         | 45.1        |\n","---------------------------------------\n","Episode: 11\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 132       |\n","|    iterations         | 3000      |\n","|    time_elapsed       | 113       |\n","|    total_timesteps    | 15000     |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | -0.083    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2999      |\n","|    policy_loss        | 39.7      |\n","|    reward             | 2.1328402 |\n","|    std                | 1         |\n","|    value_loss         | 3.11      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 133       |\n","|    iterations         | 3100      |\n","|    time_elapsed       | 116       |\n","|    total_timesteps    | 15500     |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3099      |\n","|    policy_loss        | -230      |\n","|    reward             | 1.8805013 |\n","|    std                | 1         |\n","|    value_loss         | 40.2      |\n","-------------------------------------\n","Episode: 12\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 3200       |\n","|    time_elapsed       | 120        |\n","|    total_timesteps    | 16000      |\n","| train/                |            |\n","|    entropy_loss       | -41.2      |\n","|    explained_variance | -0.00157   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3199       |\n","|    policy_loss        | -72.3      |\n","|    reward             | 0.56379193 |\n","|    std                | 1          |\n","|    value_loss         | 4.5        |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 132       |\n","|    iterations         | 3300      |\n","|    time_elapsed       | 124       |\n","|    total_timesteps    | 16500     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3299      |\n","|    policy_loss        | 133       |\n","|    reward             | 2.2489755 |\n","|    std                | 1.01      |\n","|    value_loss         | 16.8      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 133       |\n","|    iterations         | 3400      |\n","|    time_elapsed       | 127       |\n","|    total_timesteps    | 17000     |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | -0.0015   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3399      |\n","|    policy_loss        | -842      |\n","|    reward             | 6.8551507 |\n","|    std                | 1         |\n","|    value_loss         | 470       |\n","-------------------------------------\n","Episode: 13\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 133       |\n","|    iterations         | 3500      |\n","|    time_elapsed       | 131       |\n","|    total_timesteps    | 17500     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 0.103     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3499      |\n","|    policy_loss        | -69.8     |\n","|    reward             | 1.2275734 |\n","|    std                | 1         |\n","|    value_loss         | 4.2       |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 133        |\n","|    iterations         | 3600       |\n","|    time_elapsed       | 134        |\n","|    total_timesteps    | 18000      |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0.00303    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3599       |\n","|    policy_loss        | -150       |\n","|    reward             | -0.9243193 |\n","|    std                | 1.01       |\n","|    value_loss         | 20.3       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 132       |\n","|    iterations         | 3700      |\n","|    time_elapsed       | 139       |\n","|    total_timesteps    | 18500     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3699      |\n","|    policy_loss        | -97.4     |\n","|    reward             | 3.1923246 |\n","|    std                | 1.01      |\n","|    value_loss         | 14.4      |\n","-------------------------------------\n","Episode: 14\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 133      |\n","|    iterations         | 3800     |\n","|    time_elapsed       | 142      |\n","|    total_timesteps    | 19000    |\n","| train/                |          |\n","|    entropy_loss       | -41.3    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 3799     |\n","|    policy_loss        | 23.1     |\n","|    reward             | 1.563878 |\n","|    std                | 1        |\n","|    value_loss         | 0.551    |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 133       |\n","|    iterations         | 3900      |\n","|    time_elapsed       | 146       |\n","|    total_timesteps    | 19500     |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3899      |\n","|    policy_loss        | -153      |\n","|    reward             | 3.6070163 |\n","|    std                | 1         |\n","|    value_loss         | 14.7      |\n","-------------------------------------\n","Episode: 15\n","day: 1322, episode: 15\n","begin_total_asset: 1000000.00\n","end_total_asset: 2576468.81\n","total_reward: 1576468.81\n","total_cost: 5087.41\n","total_trades: 21383\n","Sharpe: 0.808\n","=================================\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 132       |\n","|    iterations         | 4000      |\n","|    time_elapsed       | 150       |\n","|    total_timesteps    | 20000     |\n","| train/                |           |\n","|    entropy_loss       | -41.2     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3999      |\n","|    policy_loss        | 18.9      |\n","|    reward             | 0.7405194 |\n","|    std                | 1         |\n","|    value_loss         | 0.282     |\n","-------------------------------------\n","======a2c Validation from:  2023-04-05 to  2023-07-07\n","Episode: 1\n","a2c Sharpe Ratio:  0.3032290971588148\n","======ddpg Training========\n","{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n","Using cuda device\n","Logging to tensorboard_log//ddpg/ddpg_441_1\n","Episode: 17\n","Episode: 18\n","Episode: 19\n","Episode: 20\n","day: 1322, episode: 20\n","begin_total_asset: 1000000.00\n","end_total_asset: 1693106.09\n","total_reward: 693106.09\n","total_cost: 998.98\n","total_trades: 18508\n","Sharpe: 0.603\n","=================================\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 4           |\n","|    fps             | 79          |\n","|    time_elapsed    | 66          |\n","|    total_timesteps | 5292        |\n","| train/             |             |\n","|    actor_loss      | 7.4         |\n","|    critic_loss     | 5.86        |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 5191        |\n","|    reward          | -0.28109372 |\n","------------------------------------\n","Episode: 21\n","Episode: 22\n","Episode: 23\n","Episode: 24\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 8           |\n","|    fps             | 79          |\n","|    time_elapsed    | 133         |\n","|    total_timesteps | 10584       |\n","| train/             |             |\n","|    actor_loss      | 5           |\n","|    critic_loss     | 1.29        |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 10483       |\n","|    reward          | -0.28109372 |\n","------------------------------------\n","Episode: 25\n","day: 1322, episode: 25\n","begin_total_asset: 1000000.00\n","end_total_asset: 1693106.09\n","total_reward: 693106.09\n","total_cost: 998.98\n","total_trades: 18508\n","Sharpe: 0.603\n","=================================\n","Episode: 26\n","Episode: 27\n","Episode: 28\n","------------------------------------\n","| time/              |             |\n","|    episodes        | 12          |\n","|    fps             | 79          |\n","|    time_elapsed    | 199         |\n","|    total_timesteps | 15876       |\n","| train/             |             |\n","|    actor_loss      | 0.384       |\n","|    critic_loss     | 0.319       |\n","|    learning_rate   | 0.0005      |\n","|    n_updates       | 15775       |\n","|    reward          | -0.28109372 |\n","------------------------------------\n","Episode: 29\n","Episode: 30\n","day: 1322, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 1693106.09\n","total_reward: 693106.09\n","total_cost: 998.98\n","total_trades: 18508\n","Sharpe: 0.603\n","=================================\n","Episode: 31\n","======ddpg Validation from:  2023-04-05 to  2023-07-07\n","Episode: 1\n","ddpg Sharpe Ratio:  -0.08225299086460591\n","======ppo Training========\n","{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cuda device\n","Logging to tensorboard_log//ppo/ppo_441_1\n","Episode: 33\n","-----------------------------------\n","| time/              |            |\n","|    fps             | 153        |\n","|    iterations      | 1          |\n","|    time_elapsed    | 13         |\n","|    total_timesteps | 2048       |\n","| train/             |            |\n","|    reward          | 0.07772229 |\n","-----------------------------------\n","Episode: 34\n","Episode: 35\n","day: 1322, episode: 35\n","begin_total_asset: 1000000.00\n","end_total_asset: 1031133.36\n","total_reward: 31133.36\n","total_cost: 244192.03\n","total_trades: 34614\n","Sharpe: 0.139\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 151         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 27          |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.020306822 |\n","|    clip_fraction        | 0.222       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.0301     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.55        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0364     |\n","|    reward               | 0.7325323   |\n","|    std                  | 1           |\n","|    value_loss           | 14.2        |\n","-----------------------------------------\n","Episode: 36\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 150         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 40          |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.019939825 |\n","|    clip_fraction        | 0.209       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.0122     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.22        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0413     |\n","|    reward               | 0.27498144  |\n","|    std                  | 1           |\n","|    value_loss           | 9.56        |\n","-----------------------------------------\n","Episode: 37\n","Episode: 38\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 151         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 54          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.017396182 |\n","|    clip_fraction        | 0.2         |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | 0.0221      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.42        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0398     |\n","|    reward               | 0.682662    |\n","|    std                  | 1.01        |\n","|    value_loss           | 12.5        |\n","-----------------------------------------\n","Episode: 39\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 150         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 67          |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.020531055 |\n","|    clip_fraction        | 0.224       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | -0.017      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 3.74        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0398     |\n","|    reward               | -0.5636574  |\n","|    std                  | 1.01        |\n","|    value_loss           | 10.3        |\n","-----------------------------------------\n","Episode: 40\n","day: 1322, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 867677.53\n","total_reward: -132322.47\n","total_cost: 226712.01\n","total_trades: 34067\n","Sharpe: 0.023\n","=================================\n","Episode: 41\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 150         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 81          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.016571041 |\n","|    clip_fraction        | 0.185       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | 0.0148      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.78        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.0363     |\n","|    reward               | 0.038964182 |\n","|    std                  | 1.01        |\n","|    value_loss           | 17.8        |\n","-----------------------------------------\n","Episode: 42\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 150         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 95          |\n","|    total_timesteps      | 14336       |\n","| train/                  |             |\n","|    approx_kl            | 0.018911857 |\n","|    clip_fraction        | 0.195       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | 0.0323      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.66        |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0357     |\n","|    reward               | -0.21484302 |\n","|    std                  | 1.01        |\n","|    value_loss           | 9.19        |\n","-----------------------------------------\n","Episode: 43\n","Episode: 44\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 150        |\n","|    iterations           | 8          |\n","|    time_elapsed         | 109        |\n","|    total_timesteps      | 16384      |\n","| train/                  |            |\n","|    approx_kl            | 0.01867793 |\n","|    clip_fraction        | 0.214      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.4      |\n","|    explained_variance   | 0.0154     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 5.26       |\n","|    n_updates            | 70         |\n","|    policy_gradient_loss | -0.0392    |\n","|    reward               | 0.9640699  |\n","|    std                  | 1.01       |\n","|    value_loss           | 12.2       |\n","----------------------------------------\n","Episode: 45\n","day: 1322, episode: 45\n","begin_total_asset: 1000000.00\n","end_total_asset: 1381375.67\n","total_reward: 381375.67\n","total_cost: 242816.93\n","total_trades: 34634\n","Sharpe: 0.390\n","=================================\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 150          |\n","|    iterations           | 9            |\n","|    time_elapsed         | 122          |\n","|    total_timesteps      | 18432        |\n","| train/                  |              |\n","|    approx_kl            | 0.020125795  |\n","|    clip_fraction        | 0.234        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -41.5        |\n","|    explained_variance   | 0.0898       |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 3.22         |\n","|    n_updates            | 80           |\n","|    policy_gradient_loss | -0.0336      |\n","|    reward               | -0.023677668 |\n","|    std                  | 1.01         |\n","|    value_loss           | 8.76         |\n","------------------------------------------\n","Episode: 46\n","Episode: 47\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 150         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 135         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.017867956 |\n","|    clip_fraction        | 0.18        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | 0.0263      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 6.09        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0361     |\n","|    reward               | -0.5044272  |\n","|    std                  | 1.01        |\n","|    value_loss           | 14.1        |\n","-----------------------------------------\n","======ppo Validation from:  2023-04-05 to  2023-07-07\n","Episode: 1\n","ppo Sharpe Ratio:  -0.060817514670728885\n","======Best Model Retraining from:  2018-01-01 to  2023-07-07\n","======Trading from:  2023-07-07 to  2023-10-05\n","Used Model:  <stable_baselines3.a2c.a2c.A2C object at 0x7b6b0de42fb0>\n","Episode: 1\n","Ensemble Strategy took:  51.08259893655777  minutes\n"]}],"source":["df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n","                                                 PPO_model_kwargs,\n","                                                 DDPG_model_kwargs,\n","                                                 timesteps_dict) if if_using_ensemble else None"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":105,"status":"ok","timestamp":1718878961829,"user":{"displayName":"Nh蘯･t Tﾄハg","userId":"06015623828132359617"},"user_tz":-420},"id":"7ub0E28nyiLB","outputId":"eaf644a0-a084-40f7-b985-d5b6ad3a24fa"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df_summary\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Iter\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 126,\n        \"max\": 441,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          126,\n          189,\n          441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Start\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2022-01-03\",\n          \"2022-04-04\",\n          \"2023-04-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val End\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2022-04-04\",\n          \"2022-07-06\",\n          \"2023-07-07\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Used\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"DDPG\",\n          \"A2C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A2C Sharpe\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.16043681519416056,\n        \"max\": 0.3809918218467061,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.024746055165678328,\n          -0.16043681519416056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PPO Sharpe\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.25906576321644814,\n        \"max\": 0.18812006385003913,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.10845397278410822,\n          -0.25906576321644814\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DDPG Sharpe\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.2529197168642002,\n        \"max\": 0.35839916368634406,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.06844717766395098,\n          -0.2529197168642002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df_summary"},"text/html":["\n","  <div id=\"df-c3df3c37-dfc5-4302-9f20-620defe6b8c0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Iter</th>\n","      <th>Val Start</th>\n","      <th>Val End</th>\n","      <th>Model Used</th>\n","      <th>A2C Sharpe</th>\n","      <th>PPO Sharpe</th>\n","      <th>DDPG Sharpe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>126</td>\n","      <td>2022-01-03</td>\n","      <td>2022-04-04</td>\n","      <td>A2C</td>\n","      <td>-0.024746</td>\n","      <td>-0.108454</td>\n","      <td>-0.068447</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>189</td>\n","      <td>2022-04-04</td>\n","      <td>2022-07-06</td>\n","      <td>A2C</td>\n","      <td>-0.160437</td>\n","      <td>-0.259066</td>\n","      <td>-0.25292</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>252</td>\n","      <td>2022-07-06</td>\n","      <td>2022-10-04</td>\n","      <td>A2C</td>\n","      <td>-0.080968</td>\n","      <td>-0.185529</td>\n","      <td>-0.094428</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>315</td>\n","      <td>2022-10-04</td>\n","      <td>2023-01-04</td>\n","      <td>A2C</td>\n","      <td>0.380992</td>\n","      <td>0.18812</td>\n","      <td>0.358399</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>378</td>\n","      <td>2023-01-04</td>\n","      <td>2023-04-05</td>\n","      <td>DDPG</td>\n","      <td>-0.050632</td>\n","      <td>-0.043434</td>\n","      <td>0.107677</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>441</td>\n","      <td>2023-04-05</td>\n","      <td>2023-07-07</td>\n","      <td>A2C</td>\n","      <td>0.303229</td>\n","      <td>-0.060818</td>\n","      <td>-0.082253</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3df3c37-dfc5-4302-9f20-620defe6b8c0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c3df3c37-dfc5-4302-9f20-620defe6b8c0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c3df3c37-dfc5-4302-9f20-620defe6b8c0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9226fcf4-137b-4459-99f3-f5c2be9d0b13\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9226fcf4-137b-4459-99f3-f5c2be9d0b13')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9226fcf4-137b-4459-99f3-f5c2be9d0b13 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_b7212feb-3424-48d6-ac81-60e2276118fa\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b7212feb-3424-48d6-ac81-60e2276118fa button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_summary');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n","0  126  2022-01-03  2022-04-04        A2C  -0.024746  -0.108454   -0.068447\n","1  189  2022-04-04  2022-07-06        A2C  -0.160437  -0.259066    -0.25292\n","2  252  2022-07-06  2022-10-04        A2C  -0.080968  -0.185529   -0.094428\n","3  315  2022-10-04  2023-01-04        A2C   0.380992    0.18812    0.358399\n","4  378  2023-01-04  2023-04-05       DDPG  -0.050632  -0.043434    0.107677\n","5  441  2023-04-05  2023-07-07        A2C   0.303229  -0.060818   -0.082253"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df_summary if if_using_ensemble else None"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
